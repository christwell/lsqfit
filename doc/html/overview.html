<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Overview and Tutorial &mdash; lsqfit 7.1.0 documentation</title>
    
    <link rel="stylesheet" href="_static/pyramid.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '7.1.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="top" title="lsqfit 7.1.0 documentation" href="index.html" />
    <link rel="next" title="Case Study: Simple Extrapolation" href="case-extrapolation.html" />
    <link rel="prev" title="lsqfit Documentation" href="index.html" />
<link rel="stylesheet" href="http://fonts.googleapis.com/css?family=Neuton&amp;subset=latin" type="text/css" media="screen" charset="utf-8" />
<link rel="stylesheet" href="http://fonts.googleapis.com/css?family=Nobile:regular,italic,bold,bolditalic&amp;subset=latin" type="text/css" media="screen" charset="utf-8" />
<!--[if lte IE 6]>
<link rel="stylesheet" href="_static/ie6.css" type="text/css" media="screen" charset="utf-8" />
<![endif]-->

  </head>
  <body role="document">

    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="case-extrapolation.html" title="Case Study: Simple Extrapolation"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="index.html" title="lsqfit Documentation"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">lsqfit 7.1.0 documentation</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="overview-and-tutorial">
<h1>Overview and Tutorial<a class="headerlink" href="#overview-and-tutorial" title="Permalink to this headline">¶</a></h1>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>The  <a class="reference internal" href="lsqfit.html#module-lsqfit" title="lsqfit: Nonlinear least squares fitting."><code class="xref py py-mod docutils literal"><span class="pre">lsqfit</span></code></a> module is designed to facilitate least-squares fitting of
noisy data by multi-dimensional, nonlinear functions of arbitrarily many
parameters, each with a (Bayesian) prior.  <a class="reference internal" href="lsqfit.html#module-lsqfit" title="lsqfit: Nonlinear least squares fitting."><code class="xref py py-mod docutils literal"><span class="pre">lsqfit</span></code></a> makes heavy use of
another module, <code class="xref py py-mod docutils literal"><span class="pre">gvar</span></code> (distributed separately), which provides tools
that simplify the analysis of error propagation, and also the creation of
complicated multi-dimensional Gaussian distributions. The power of the
<code class="xref py py-mod docutils literal"><span class="pre">gvar</span></code> module, particularly for correlated distributions, is a feature
that distinguishes <a class="reference internal" href="lsqfit.html#module-lsqfit" title="lsqfit: Nonlinear least squares fitting."><code class="xref py py-mod docutils literal"><span class="pre">lsqfit</span></code></a> from standard fitting packages, as
demonstrated below.</p>
<p>The following (complete) code illustrates basic usage of <a class="reference internal" href="lsqfit.html#module-lsqfit" title="lsqfit: Nonlinear least squares fitting."><code class="xref py py-mod docutils literal"><span class="pre">lsqfit</span></code></a>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">gvar</span> <span class="kn">as</span> <span class="nn">gv</span>
<span class="kn">import</span> <span class="nn">lsqfit</span>

<span class="n">y</span> <span class="o">=</span> <span class="p">{</span>                      <span class="c"># data for the dependent variable</span>
    <span class="s">&#39;data1&#39;</span> <span class="p">:</span> <span class="n">gv</span><span class="o">.</span><span class="n">gvar</span><span class="p">([</span><span class="mf">1.376</span><span class="p">,</span> <span class="mf">2.010</span><span class="p">],</span> <span class="p">[[</span> <span class="mf">0.0047</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">],</span> <span class="p">[</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.056</span><span class="p">]]),</span>
    <span class="s">&#39;data2&#39;</span> <span class="p">:</span> <span class="n">gv</span><span class="o">.</span><span class="n">gvar</span><span class="p">([</span><span class="mf">1.329</span><span class="p">,</span> <span class="mf">1.582</span><span class="p">],</span> <span class="p">[[</span> <span class="mf">0.0047</span><span class="p">,</span> <span class="mf">0.0067</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.0067</span><span class="p">,</span> <span class="mf">0.0136</span><span class="p">]]),</span>
    <span class="s">&#39;b/a&#39;</span>   <span class="p">:</span> <span class="n">gv</span><span class="o">.</span><span class="n">gvar</span><span class="p">(</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
    <span class="p">}</span>
<span class="n">x</span> <span class="o">=</span> <span class="p">{</span>                      <span class="c"># independent variable</span>
    <span class="s">&#39;data1&#39;</span> <span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]),</span>
    <span class="s">&#39;data2&#39;</span> <span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])</span>
    <span class="p">}</span>
<span class="n">prior</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="n">gv</span><span class="o">.</span><span class="n">gvar</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">b</span><span class="o">=</span><span class="n">gv</span><span class="o">.</span><span class="n">gvar</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">fcn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>             <span class="c"># fit function of x and parameters p</span>
   <span class="n">ans</span> <span class="o">=</span> <span class="p">{}</span>
   <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="p">[</span><span class="s">&#39;data1&#39;</span><span class="p">,</span> <span class="s">&#39;data2&#39;</span><span class="p">]:</span>
      <span class="n">ans</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">gv</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="s">&#39;a&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">x</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">p</span><span class="p">[</span><span class="s">&#39;b&#39;</span><span class="p">])</span>
   <span class="n">ans</span><span class="p">[</span><span class="s">&#39;b/a&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">p</span><span class="p">[</span><span class="s">&#39;b&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">p</span><span class="p">[</span><span class="s">&#39;a&#39;</span><span class="p">]</span>
   <span class="k">return</span> <span class="n">ans</span>

<span class="c"># do the fit</span>
<span class="n">fit</span> <span class="o">=</span> <span class="n">lsqfit</span><span class="o">.</span><span class="n">nonlinear_fit</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">prior</span><span class="o">=</span><span class="n">prior</span><span class="p">,</span> <span class="n">fcn</span><span class="o">=</span><span class="n">fcn</span><span class="p">,</span> <span class="n">debug</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">fit</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">maxline</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>     <span class="c"># print standard summary of fit</span>

<span class="n">p</span> <span class="o">=</span> <span class="n">fit</span><span class="o">.</span><span class="n">p</span>                  <span class="c"># best-fit values for parameters</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="n">p</span><span class="p">[</span><span class="s">&#39;a&#39;</span><span class="p">],</span> <span class="n">b</span><span class="o">=</span><span class="n">p</span><span class="p">[</span><span class="s">&#39;b&#39;</span><span class="p">])</span>
<span class="n">outputs</span><span class="p">[</span><span class="s">&#39;b/a&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">p</span><span class="p">[</span><span class="s">&#39;b&#39;</span><span class="p">]</span><span class="o">/</span><span class="n">p</span><span class="p">[</span><span class="s">&#39;a&#39;</span><span class="p">]</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">prior</span><span class="o">=</span><span class="n">prior</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">gv</span><span class="o">.</span><span class="n">fmt_values</span><span class="p">(</span><span class="n">outputs</span><span class="p">))</span>              <span class="c"># tabulate outputs</span>
<span class="k">print</span><span class="p">(</span><span class="n">gv</span><span class="o">.</span><span class="n">fmt_errorbudget</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">inputs</span><span class="p">))</span> <span class="c"># print error budget for outputs</span>
</pre></div>
</div>
<p>This code fits the function <code class="docutils literal"><span class="pre">f(x,a,b)=</span> <span class="pre">exp(a+b*x)</span></code> (see <code class="docutils literal"><span class="pre">fcn(x,p)</span></code>)
to two sets of data, labeled <code class="docutils literal"><span class="pre">data1</span></code> and <code class="docutils literal"><span class="pre">data2</span></code>, by varying parameters
<code class="docutils literal"><span class="pre">a</span></code> and <code class="docutils literal"><span class="pre">b</span></code> until <code class="docutils literal"><span class="pre">f(x['data1'],a,b)</span></code> and <code class="docutils literal"><span class="pre">f(x['data2'],a,b)</span></code>
equal <code class="docutils literal"><span class="pre">y['data1']</span></code> and <code class="docutils literal"><span class="pre">y['data2']</span></code>, respectively, to within the
<code class="docutils literal"><span class="pre">y</span></code>s&#8217; errors. The means and covariance matrices for the <code class="docutils literal"><span class="pre">y</span></code>s are
specified in the <code class="docutils literal"><span class="pre">gv.gvar(...)</span></code>s used to create them: for example,</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="s">&#39;data1&#39;</span><span class="p">])</span>
<span class="go">[1.376(69) 2.01(24)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="s">&#39;data1&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> <span class="s">&quot;+-&quot;</span><span class="p">,</span> <span class="n">y</span><span class="p">[</span><span class="s">&#39;data1&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">sdev</span><span class="p">)</span>
<span class="go">1.376 +- 0.068556546004</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">gv</span><span class="o">.</span><span class="n">evalcov</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="s">&#39;data1&#39;</span><span class="p">]))</span>   <span class="c"># covariance matrix</span>
<span class="go">[[ 0.0047  0.01  ]</span>
<span class="go"> [ 0.01    0.056 ]]</span>
</pre></div>
</div>
<p>shows the means, standard deviations and covariance matrix for the data in
the first data set (0.0685565 is the square root of the 0.0047 in
the covariance matrix). The dictionary <code class="docutils literal"><span class="pre">prior</span></code> gives <em>a priori</em> estimates
for the two parameters, <code class="docutils literal"><span class="pre">a</span></code> and <code class="docutils literal"><span class="pre">b</span></code>: each is assumed to be 0.5±0.5
before fitting. The parameters <code class="docutils literal"><span class="pre">p[k]</span></code> in the fit function <code class="docutils literal"><span class="pre">fcn(x,</span> <span class="pre">p)</span></code>
are stored in a dictionary having the same keys and layout as
<code class="docutils literal"><span class="pre">prior</span></code> (since <code class="docutils literal"><span class="pre">prior</span></code> specifies the fit parameters for
the fitter). In addition, there is an extra piece of input data,
<code class="docutils literal"><span class="pre">y['b/a']</span></code>, which indicates that <code class="docutils literal"><span class="pre">b/a</span></code> is 2±0.5. The fit
function for this data is simply the ratio <code class="docutils literal"><span class="pre">b/a</span></code> (represented by
<code class="docutils literal"><span class="pre">p['b']/p['a']</span></code> in fit function <code class="docutils literal"><span class="pre">fcn(x,p)</span></code>). The fit function returns
a dictionary having the same keys and layout as the input data <code class="docutils literal"><span class="pre">y</span></code>.</p>
<p>The output from the code sample above is:</p>
<div class="highlight-python"><div class="highlight"><pre>Least Square Fit:
  chi2/dof [dof] = 0.17 [5]    Q = 0.97    logGBF = 0.65538

Parameters:
              a   0.253 (32)     [  0.50 (50) ]  
              b   0.449 (65)     [  0.50 (50) ]  

Fit:
        key        y[key]     f(p)[key]
---------------------------------------
        b/a     2.00 (50)     1.78 (30)  
    data1 0    1.376 (69)    1.347 (46)  
          1     2.01 (24)     2.02 (16)  
    data2 0    1.329 (69)    1.347 (46)  
          1     1.58 (12)    1.612 (82)  

Settings:
  svdcut/n = 1e-15/0    reltol/abstol = 0.0001/0    (itns/time = 5/0.0)

Values:
                  a: 0.253(32)           
                b/a: 1.78(30)            
                  b: 0.449(65)           

Partial % Errors:
                   a       b/a         b
----------------------------------------
        y:     12.75     16.72     14.30
    prior:      0.92      1.58      1.88
----------------------------------------
    total:     12.78     16.80     14.42
</pre></div>
</div>
<p>The best-fit values for <code class="docutils literal"><span class="pre">a</span></code> and <code class="docutils literal"><span class="pre">b</span></code> are 0.253(32) and
0.449(65), respectively; and the best-fit result for <code class="docutils literal"><span class="pre">b/a</span></code> is
1.78(30), which, because of correlations, is slightly more accurate
than might be expected from the separate errors for <code class="docutils literal"><span class="pre">a</span></code> and <code class="docutils literal"><span class="pre">b</span></code>. The
error budget for each of these three quantities is tabulated at the end and
shows that the bulk of the error in each case comes from uncertainties in
the <code class="docutils literal"><span class="pre">y</span></code> data, with only small contributions from uncertainties in the
priors <code class="docutils literal"><span class="pre">prior</span></code>. The fit results corresponding to each piece of input data
are also tabulated (<code class="docutils literal"><span class="pre">Fit:</span> <span class="pre">...</span></code>); the agreement is excellent, as expected
given that the <code class="docutils literal"><span class="pre">chi**2</span></code> per degree of freedom is only 0.17.</p>
<p>Note that the constraint in <code class="docutils literal"><span class="pre">y</span></code> on <code class="docutils literal"><span class="pre">b/a</span></code> in this example is much tighter
than the constraints on <code class="docutils literal"><span class="pre">a</span></code> and <code class="docutils literal"><span class="pre">b</span></code> separately. This suggests a variation
on the previous code, where the tight restriction on <code class="docutils literal"><span class="pre">b/a</span></code> is built into the
prior rather than <code class="docutils literal"><span class="pre">y</span></code>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="o">...</span> <span class="k">as</span> <span class="n">before</span> <span class="o">...</span>

<span class="n">y</span> <span class="o">=</span> <span class="p">{</span>                      <span class="c"># data for the dependent variable</span>
    <span class="s">&#39;data1&#39;</span> <span class="p">:</span> <span class="n">gv</span><span class="o">.</span><span class="n">gvar</span><span class="p">([</span><span class="mf">1.376</span><span class="p">,</span> <span class="mf">2.010</span><span class="p">],</span> <span class="p">[[</span> <span class="mf">0.0047</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">],</span> <span class="p">[</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.056</span><span class="p">]]),</span>
    <span class="s">&#39;data2&#39;</span> <span class="p">:</span> <span class="n">gv</span><span class="o">.</span><span class="n">gvar</span><span class="p">([</span><span class="mf">1.329</span><span class="p">,</span> <span class="mf">1.582</span><span class="p">],</span> <span class="p">[[</span> <span class="mf">0.0047</span><span class="p">,</span> <span class="mf">0.0067</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.0067</span><span class="p">,</span> <span class="mf">0.0136</span><span class="p">]])</span>
    <span class="p">}</span>
<span class="n">x</span> <span class="o">=</span> <span class="p">{</span>                      <span class="c"># independent variable</span>
    <span class="s">&#39;data1&#39;</span> <span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]),</span>
    <span class="s">&#39;data2&#39;</span> <span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])</span>
    <span class="p">}</span>
<span class="n">prior</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="n">gv</span><span class="o">.</span><span class="n">gvar</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))</span>
<span class="n">prior</span><span class="p">[</span><span class="s">&#39;b&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prior</span><span class="p">[</span><span class="s">&#39;a&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">gv</span><span class="o">.</span><span class="n">gvar</span><span class="p">(</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">fcn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>             <span class="c"># fit function of x and parameters p[k]</span>
   <span class="n">ans</span> <span class="o">=</span> <span class="p">{}</span>
   <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="p">[</span><span class="s">&#39;data1&#39;</span><span class="p">,</span> <span class="s">&#39;data2&#39;</span><span class="p">]:</span>
      <span class="n">ans</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">gv</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="s">&#39;a&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">x</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">*</span><span class="n">p</span><span class="p">[</span><span class="s">&#39;b&#39;</span><span class="p">])</span>
   <span class="k">return</span> <span class="n">ans</span>

<span class="o">...</span> <span class="k">as</span> <span class="n">before</span> <span class="o">...</span>
</pre></div>
</div>
<p>Here the dependent data <code class="docutils literal"><span class="pre">y</span></code> no longer has an entry for <code class="docutils literal"><span class="pre">b/a</span></code>, and neither
do results from the fit function; but the prior for <code class="docutils literal"><span class="pre">b</span></code> is now 2±0.5
times the prior for <code class="docutils literal"><span class="pre">a</span></code>, thereby introducing a correlation that
limits the ratio <code class="docutils literal"><span class="pre">b/a</span></code> to be 2±0.5 in the fit. This code gives almost
identical results to the first one &#8212; very slightly less accurate, since
there is less input data. We can often move information from the <code class="docutils literal"><span class="pre">y</span></code> data to
the prior or back since both are forms of input information.</p>
<p>There are several things worth noting from this example:</p>
<blockquote>
<div><ul class="simple">
<li>The input data (<code class="docutils literal"><span class="pre">y</span></code>) is expressed in terms of Gaussian random
variables &#8212; quantities with means and a covariance matrix. These are
represented by objects of type <code class="xref py py-class docutils literal"><span class="pre">gvar.GVar</span></code> in the code; module
<code class="xref py py-mod docutils literal"><span class="pre">gvar</span></code> has a variety of tools for creating and manipulating
Gaussian random variables (also see below).</li>
<li>The input data is stored in a dictionary (<code class="docutils literal"><span class="pre">y</span></code>) whose values can
be <code class="xref py py-class docutils literal"><span class="pre">gvar.GVar</span></code>s or arrays of <code class="xref py py-class docutils literal"><span class="pre">gvar.GVar</span></code>s. The use of a dictionary allows for
far greater flexibility than, say, an array. The fit function
(<code class="docutils literal"><span class="pre">fcn(x,</span> <span class="pre">p)</span></code>) has to return a dictionary with the same layout as
that of <code class="docutils literal"><span class="pre">y</span></code> (that is, with the same keys and where the value for
each key has the same shape as the corresponding value in <code class="docutils literal"><span class="pre">y</span></code>).
<a class="reference internal" href="lsqfit.html#module-lsqfit" title="lsqfit: Nonlinear least squares fitting."><code class="xref py py-mod docutils literal"><span class="pre">lsqfit</span></code></a> allows <code class="docutils literal"><span class="pre">y</span></code> to be an array instead of a dictionary,
which might be preferable for very simple fits (but usually not
otherwise).</li>
<li>The independent data (<code class="docutils literal"><span class="pre">x</span></code>) can be anything; it is simply passed
through the fit code to the fit function <code class="docutils literal"><span class="pre">fcn(x,p)</span></code>. It can
also be omitted altogether, in which case the fit function
depends only upon the parameters: <code class="docutils literal"><span class="pre">fcn(p)</span></code>.</li>
<li>The fit parameters (<code class="docutils literal"><span class="pre">p</span></code> in <code class="docutils literal"><span class="pre">fcn(x,p)</span></code>) are also stored in a
dictionary whose values are <code class="xref py py-class docutils literal"><span class="pre">gvar.GVar</span></code>s or arrays of <code class="xref py py-class docutils literal"><span class="pre">gvar.GVar</span></code>s. Again this
allows for great flexibility. The layout of the parameter dictionary
is copied from that of the prior (<code class="docutils literal"><span class="pre">prior</span></code>). Again <code class="docutils literal"><span class="pre">p</span></code> can be a
single array instead of a dictionary, if that simplifies the code
(which is usually not the case).</li>
<li>The best-fit values of the fit parameters (<code class="docutils literal"><span class="pre">fit.p[k]</span></code>) are also
<code class="xref py py-class docutils literal"><span class="pre">gvar.GVar</span></code>s and these capture statistical correlations between different
parameters that are indicated by the fit. These output parameters can
be combined in arithmetic expressions, using standard operators and
standard functions, to obtain derived quantities. These operations
take account of and track statistical correlations.</li>
<li>Function <code class="xref py py-func docutils literal"><span class="pre">gvar.fmt_errorbudget()</span></code> is a useful tool for assessing
the origins (<code class="docutils literal"><span class="pre">inputs</span></code>) of the statistical errors obtained in various
final results (<code class="docutils literal"><span class="pre">outputs</span></code>). It is particularly useful for analyzing
the impact of the <em>a priori</em> uncertainties encoded in the prior
(<code class="docutils literal"><span class="pre">prior</span></code>).</li>
<li>Parameter <code class="docutils literal"><span class="pre">debug=True</span></code> is set in <a class="reference internal" href="lsqfit.html#lsqfit.nonlinear_fit" title="lsqfit.nonlinear_fit"><code class="xref py py-class docutils literal"><span class="pre">lsqfit.nonlinear_fit</span></code></a>. This is a good idea,
particularly in the eary stages of a project, because it causes the
code to check for various common errors and give more intelligible
error messages than would otherwise arise. This parameter can be dropped
once code development is over.</li>
<li>The priors for the fit parameters specify Gaussian distributions,
characterized by the means and standard deviations given
<code class="docutils literal"><span class="pre">gv.gvar(...)</span></code>. Some other distributions become available if argument
<code class="docutils literal"><span class="pre">extend=True</span></code> is included in the call to <a class="reference internal" href="lsqfit.html#lsqfit.nonlinear_fit" title="lsqfit.nonlinear_fit"><code class="xref py py-class docutils literal"><span class="pre">lsqfit.nonlinear_fit</span></code></a>.  The
distribution for parameter <code class="docutils literal"><span class="pre">a</span></code>, for example, can then be switched to a
log-normal distribution by replacing <code class="docutils literal"><span class="pre">a=gv.gvar(0.5,</span> <span class="pre">0.5)</span></code> with
<code class="docutils literal"><span class="pre">loga=gv.log(gv.gvar(0.5,0.5))</span></code> in the prior. This change would
be desirable if we knew <em>a priori</em> that parameter <code class="docutils literal"><span class="pre">a</span></code> is positive
since this is guaranteed with a log-normal distribution.</li>
</ul>
</div></blockquote>
<p>What follows is a tutorial that demonstrates in greater detail how to
use these modules in some standard variations on the data fitting problem.
As above, code for the examples is specified completely and so can be copied
into a file, and run as is. It can also be modified, allowing for
experimentation.</p>
<p>Another way to learn about the modules is to examine the case studies
that follow this section. Each focuses on a single problem, again with
the full code and data to allow for experimentation.</p>
<p><em>About Printing:</em> The examples in this tutorial use the <code class="docutils literal"><span class="pre">print</span></code> function
as it is used in Python 3. Drop the outermost parenthesis in each <code class="docutils literal"><span class="pre">print</span></code>
statement if using Python 2; or add</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span>
</pre></div>
</div>
<p>at the start of your file.</p>
</div>
<div class="section" id="gaussian-random-variables-and-error-propagation">
<h2>Gaussian Random Variables and Error Propagation<a class="headerlink" href="#gaussian-random-variables-and-error-propagation" title="Permalink to this headline">¶</a></h2>
<p>The inputs and outputs of a nonlinear least squares analysis are probability
distributions, and these distributions will be Gaussian provided the input
data are sufficiently accurate. <a class="reference internal" href="lsqfit.html#module-lsqfit" title="lsqfit: Nonlinear least squares fitting."><code class="xref py py-mod docutils literal"><span class="pre">lsqfit</span></code></a> assumes this to be the case.
(It also provides tests for non-Gaussian behavior, together with
methods for dealing with such behavior.)
One of the most distinctive features of <a class="reference internal" href="lsqfit.html#module-lsqfit" title="lsqfit: Nonlinear least squares fitting."><code class="xref py py-mod docutils literal"><span class="pre">lsqfit</span></code></a> is that it is
built around a class, <code class="xref py py-class docutils literal"><span class="pre">gvar.GVar</span></code>, of objects that can be used to
represent arbitrarily complicated Gaussian distributions
&#8212; that is, they represent <em>Gaussian random variables</em> that specify the means and
covariance matrix of the probability distributions.
The input data for a fit are represented
by a collection of <code class="xref py py-class docutils literal"><span class="pre">gvar.GVar</span></code>s that specify both the values and possible
errors in the input values. The result of a fit is a collection of
<code class="xref py py-class docutils literal"><span class="pre">gvar.GVar</span></code>s specifying the best-fit values for the fit parameters and the
estimated uncertainties in those values.</p>
<p><code class="xref py py-class docutils literal"><span class="pre">gvar.GVar</span></code>s are defined in the <code class="xref py py-mod docutils literal"><span class="pre">gvar</span></code> module.
There are four important things to know about them (see the
<code class="xref py py-mod docutils literal"><span class="pre">gvar</span></code> documentation for more details):</p>
<blockquote>
<div><ol class="arabic">
<li><p class="first"><code class="xref py py-class docutils literal"><span class="pre">gvar.GVar</span></code>s are created by <code class="xref py py-meth docutils literal"><span class="pre">gvar.gvar()</span></code>, individually or in
groups: for example,</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">gvar</span> <span class="kn">as</span> <span class="nn">gv</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">gv</span><span class="o">.</span><span class="n">gvar</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">),</span> <span class="n">gv</span><span class="o">.</span><span class="n">gvar</span><span class="p">(</span><span class="s">&#39;1.0 +- 0.2&#39;</span><span class="p">),</span> <span class="n">gv</span><span class="o">.</span><span class="n">gvar</span><span class="p">(</span><span class="s">&#39;1.0(4)&#39;</span><span class="p">))</span>
<span class="go">1.00(10) 1.00(20) 1.00(40)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">gv</span><span class="o">.</span><span class="n">gvar</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.41</span><span class="p">]))</span>
<span class="go">[1.00(10) 1.00(20) 1.00(41)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">gv</span><span class="o">.</span><span class="n">gvar</span><span class="p">([</span><span class="s">&#39;1.0(1)&#39;</span><span class="p">,</span> <span class="s">&#39;1.0(2)&#39;</span><span class="p">,</span> <span class="s">&#39;1.00(41)&#39;</span><span class="p">]))</span>
<span class="go">[1.00(10) 1.00(20) 1.00(41)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">gv</span><span class="o">.</span><span class="n">gvar</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="s">&#39;1.0(1)&#39;</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="p">[</span><span class="s">&#39;1.0(2)&#39;</span><span class="p">,</span> <span class="s">&#39;1.0(4)&#39;</span><span class="p">])))</span>
<span class="go">{&#39;a&#39;: 1.00(10),&#39;b&#39;: array([1.00(20), 1.00(40)], dtype=object)}</span>
</pre></div>
</div>
<p><code class="xref py py-mod docutils literal"><span class="pre">gvar</span></code> uses the compact notation 1.234(22) to represent
1.234±0.022 &#8212; the digits in parentheses indicate the
uncertainty in the rightmost corresponding digits quoted for the
mean value. Very large (or small) numbers use a notation like
1.234(22)e10.</p>
</li>
<li><p class="first"><code class="xref py py-class docutils literal"><span class="pre">gvar.GVar</span></code>s describe not only means and standard deviations, but also
statistical correlations between different objects. For example, the
<code class="xref py py-class docutils literal"><span class="pre">gvar.GVar</span></code>s created by</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">gvar</span> <span class="kn">as</span> <span class="nn">gv</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">gv</span><span class="o">.</span><span class="n">gvar</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.010001</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="go">1.00(10) 1.00(10)</span>
</pre></div>
</div>
<p>both have means of <code class="docutils literal"><span class="pre">1</span></code> and standard deviations equal to or
very close to <code class="docutils literal"><span class="pre">0.1</span></code>, but the ratio <code class="docutils literal"><span class="pre">b/a</span></code> has a
standard deviation that is 100x smaller:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">b</span> <span class="o">/</span> <span class="n">a</span><span class="p">)</span>
<span class="go">1.0000(10)</span>
</pre></div>
</div>
<p>This is because the covariance matrix specified for <code class="docutils literal"><span class="pre">a</span></code> and <code class="docutils literal"><span class="pre">b</span></code>
when they were created has large, positive off-diagonal elements:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">gv</span><span class="o">.</span><span class="n">evalcov</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">]))</span>         <span class="c"># covariance matrix</span>
<span class="go">[[ 0.01      0.01    ]</span>
<span class="go"> [ 0.01      0.010001]]</span>
</pre></div>
</div>
<p>These off-diagonal elements imply that <code class="docutils literal"><span class="pre">a</span></code> and <code class="docutils literal"><span class="pre">b</span></code> are strongly
correlated, which means that <code class="docutils literal"><span class="pre">b/a</span></code> or <code class="docutils literal"><span class="pre">b-a</span></code> will have
much smaller uncertainties than <code class="docutils literal"><span class="pre">a</span></code> or <code class="docutils literal"><span class="pre">b</span></code> separately. The
correlation coefficient for <code class="docutils literal"><span class="pre">a</span></code> and <code class="docutils literal"><span class="pre">b</span></code> is 0.99995:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">gv</span><span class="o">.</span><span class="n">evalcorr</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">]))</span>        <span class="c"># correlation matrix</span>
<span class="go">[[ 1.       0.99995]</span>
<span class="go"> [ 0.99995  1.     ]]</span>
</pre></div>
</div>
</li>
<li><p class="first"><code class="xref py py-class docutils literal"><span class="pre">gvar.GVar</span></code>s can be used in arithmetic expressions or as arguments
to pure-Python functions. The results are also <code class="xref py py-class docutils literal"><span class="pre">gvar.GVar</span></code>s. Covariances
are propagated through these expressions following the usual rules,
(automatically) preserving information about correlations. For
example, the <code class="xref py py-class docutils literal"><span class="pre">gvar.GVar</span></code>s <code class="docutils literal"><span class="pre">a</span></code> and <code class="docutils literal"><span class="pre">b</span></code> above could have been created
using the following code:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">gv</span><span class="o">.</span><span class="n">gvar</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">gv</span><span class="o">.</span><span class="n">gvar</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="go">1.00(10) 1.00(10)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">b</span> <span class="o">/</span> <span class="n">a</span><span class="p">)</span>
<span class="go">1.0000(10)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">gv</span><span class="o">.</span><span class="n">evalcov</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">]))</span>
<span class="go">[[ 0.01      0.01    ]</span>
<span class="go"> [ 0.01      0.010001]]</span>
</pre></div>
</div>
<p>The correlation is obvious from this code: <code class="docutils literal"><span class="pre">b</span></code> is equal to <code class="docutils literal"><span class="pre">a</span></code>
plus a very small correction. From these variables we can
create new variables that are also highly correlated:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">gv</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">a</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">b</span> <span class="o">*</span> <span class="n">gv</span><span class="o">.</span><span class="n">cosh</span><span class="p">(</span><span class="n">a</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">y</span> <span class="o">/</span> <span class="n">x</span><span class="p">)</span>
<span class="go">0.69(10) 1.13(14) 1.627(34)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">gv</span><span class="o">.</span><span class="n">evalcov</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">])</span>
<span class="go">[[ 0.01        0.01388174]</span>
<span class="go"> [ 0.01388174  0.01927153]]</span>
</pre></div>
</div>
<p>The <code class="xref py py-mod docutils literal"><span class="pre">gvar</span></code> module defines versions of the standard Python
functions (<code class="docutils literal"><span class="pre">sin</span></code>, <code class="docutils literal"><span class="pre">cos</span></code>, ...) that work with <code class="xref py py-class docutils literal"><span class="pre">gvar.GVar</span></code>s. Most any
numeric pure-Python function will work with them as well. Numeric
functions that are compiled in C or other low-level languages
generally do not work with <code class="xref py py-class docutils literal"><span class="pre">gvar.GVar</span></code>s; they should be replaced by
equivalent pure-Python functions if they are needed for <code class="xref py py-class docutils literal"><span class="pre">gvar.GVar</span></code>-valued
arguments. See the <code class="xref py py-mod docutils literal"><span class="pre">gvar</span></code> documentation for more
information.</p>
<p>The fact that correlation information is preserved <em>automatically</em>
through arbitrarily complicated arithmetic is what makes
<code class="xref py py-class docutils literal"><span class="pre">gvar.GVar</span></code>s particularly useful. This is accomplished using <em>automatic
differentiation</em> to compute the derivatives of any <em>derived</em> <code class="xref py py-class docutils literal"><span class="pre">gvar.GVar</span></code>
with respect to the <em>primary</em> <code class="xref py py-class docutils literal"><span class="pre">gvar.GVar</span></code>s (those defined using
<code class="xref py py-func docutils literal"><span class="pre">gvar.gvar()</span></code>) from which it was created. As a result, for example,
we need not provide derivatives of fit functions for <a class="reference internal" href="lsqfit.html#module-lsqfit" title="lsqfit: Nonlinear least squares fitting."><code class="xref py py-mod docutils literal"><span class="pre">lsqfit</span></code></a>
(which are needed for the fit) since they are computed implicitly
by the fitter from the fit function itself. Also
it becomes trivial to build correlations into the priors used
in fits, and to analyze the propagation of errors through
complicated functions of the parameters after the fit.</p>
</li>
<li><p class="first">Storing <code class="xref py py-class docutils literal"><span class="pre">gvar.GVar</span></code>s in a file for later use is somewhat complicated
because one generally wants to hold onto their correlations as well
as their mean values and standard deviations. One easy way to do
this is to put all of the <code class="xref py py-class docutils literal"><span class="pre">gvar.GVar</span></code>s to be saved into a single
dictionary object of type <code class="xref py py-class docutils literal"><span class="pre">gvar.BufferDict</span></code>, and then to save the
<code class="xref py py-class docutils literal"><span class="pre">gvar.BufferDict</span></code> using Python&#8217;s <code class="xref py py-mod docutils literal"><span class="pre">pickle</span></code> module: for example,
using the variables defined above,</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pickle</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">buffer</span> <span class="o">=</span> <span class="n">gv</span><span class="o">.</span><span class="n">BufferDict</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="n">b</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="nb">buffer</span><span class="p">)</span>
<span class="go">{&#39;a&#39;: 1.00(10),&#39;b&#39;: 1.00(10),&#39;x&#39;: 0.69(10),&#39;y&#39;: 1.13(14)}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="nb">buffer</span><span class="p">,</span> <span class="nb">open</span><span class="p">(</span><span class="s">&#39;outputfile.p&#39;</span><span class="p">,</span> <span class="s">&#39;wb&#39;</span><span class="p">))</span>
</pre></div>
</div>
<p>This creates a file named <code class="docutils literal"><span class="pre">'outputfile.p'</span></code> containing the <code class="xref py py-class docutils literal"><span class="pre">gvar.GVar</span></code>s.
Loading the file into a Python code later recovers the <code class="xref py py-class docutils literal"><span class="pre">gvar.BufferDict</span></code>
with correlations intact:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="nb">buffer</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s">&#39;outputfile.p&#39;</span><span class="p">,</span> <span class="s">&#39;rb&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="nb">buffer</span><span class="p">)</span>
<span class="go">{&#39;a&#39;: 1.00(10),&#39;b&#39;: 1.00(10),&#39;x&#39;: 0.69(10),&#39;y&#39;: 1.13(14)}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="nb">buffer</span><span class="p">[</span><span class="s">&#39;y&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="nb">buffer</span><span class="p">[</span><span class="s">&#39;x&#39;</span><span class="p">])</span>
<span class="go">1.627(34)</span>
</pre></div>
</div>
<p><code class="xref py py-class docutils literal"><span class="pre">gvar.BufferDict</span></code>s were created specifically to handle <code class="xref py py-class docutils literal"><span class="pre">gvar.GVar</span></code>s,
although they can be quite useful with other data types as well.
The values in a pickled <code class="xref py py-class docutils literal"><span class="pre">gvar.BufferDict</span></code> can be individual <code class="xref py py-class docutils literal"><span class="pre">gvar.GVar</span></code>s or
arbitrary <code class="xref py py-mod docutils literal"><span class="pre">numpy</span></code> arrays of <code class="xref py py-class docutils literal"><span class="pre">gvar.GVar</span></code>s. See the <code class="xref py py-mod docutils literal"><span class="pre">gvar</span></code>
docmentation for more information.</p>
</li>
</ol>
</div></blockquote>
<p>There is considerably more information about <code class="xref py py-class docutils literal"><span class="pre">gvar.GVar</span></code>s in the documentation for
module <code class="xref py py-mod docutils literal"><span class="pre">gvar</span></code>.</p>
</div>
<div class="section" id="basic-fits">
<span id="id1"></span><h2>Basic Fits<a class="headerlink" href="#basic-fits" title="Permalink to this headline">¶</a></h2>
<p>A fit analysis typically requires three types of input: 1) fit data
<code class="docutils literal"><span class="pre">x,y</span></code> (or possibly just <code class="docutils literal"><span class="pre">y</span></code>); 2) a function <code class="docutils literal"><span class="pre">y</span> <span class="pre">=</span> <span class="pre">f(x,</span> <span class="pre">p)</span></code> relating
values of <code class="docutils literal"><span class="pre">y</span></code> to to values of <code class="docutils literal"><span class="pre">x</span></code> and a set of fit parameters <code class="docutils literal"><span class="pre">p</span></code>
(if there is no <code class="docutils literal"><span class="pre">x</span></code>, then <code class="docutils literal"><span class="pre">y</span> <span class="pre">=</span> <span class="pre">f(p)</span></code>);
and 3) some <em>a priori</em> idea about the fit parameters&#8217; values. The <em>a priori</em>
information about a parameter could be fairly imprecise &#8212; for example,
the parameter is order 1. The point of
the fit is to improve our knowledge of the parameter values, beyond
our <em>a priori</em> impressions, by analyzing the fit data. We now show how
to do this using the <a class="reference internal" href="lsqfit.html#module-lsqfit" title="lsqfit: Nonlinear least squares fitting."><code class="xref py py-mod docutils literal"><span class="pre">lsqfit</span></code></a> module.</p>
<p>For this example, we use
fake data generated by a function, <code class="docutils literal"><span class="pre">make_data()</span></code>, that is described
at the end of this section. The function call <code class="docutils literal"><span class="pre">x,y</span> <span class="pre">=</span> <span class="pre">make_data()</span></code>
generates 15 values for <code class="docutils literal"><span class="pre">x</span></code>, equal to <code class="docutils literal"><span class="pre">1,2,3..10,12,14..20</span></code>,
and 15 values for <code class="docutils literal"><span class="pre">y</span></code>, where each <code class="docutils literal"><span class="pre">y</span></code> is obtained by adding
random noise to the value
of a function of the corresponding <code class="docutils literal"><span class="pre">x</span></code>. The function of <code class="docutils literal"><span class="pre">x</span></code> we use is:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="nb">sum</span><span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">E</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">x</span><span class="p">)</span>  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">))</span>
</pre></div>
</div>
<p>where <code class="docutils literal"><span class="pre">a[i]=0.4</span></code> and <code class="docutils literal"><span class="pre">E[i]=0.9*(i+1)</span></code>.
The result is a set of random <code class="docutils literal"><span class="pre">y</span></code>s with correlated statistical errors:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="go">[0.2752(27) 0.07951(80) ... ]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">gv</span><span class="o">.</span><span class="n">evalcov</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>              <span class="c"># covariance matrix</span>
<span class="go">[[  7.52900382e-06   2.18173029e-06   7.95744444e-07 ... ]</span>
<span class="go"> [  2.18173029e-06   6.33815228e-07   2.31761675e-07 ... ]</span>
<span class="go"> [  7.95744444e-07   2.31761675e-07   8.49651978e-08 ... ]</span>
<span class="go"> ...</span>
<span class="go">]</span>
</pre></div>
</div>
<p>Our goal is to fit this data for <code class="docutils literal"><span class="pre">y</span></code>, as a function of <code class="docutils literal"><span class="pre">x</span></code>,
and obtain estimates for the parameters <code class="docutils literal"><span class="pre">a[i]</span></code> and <code class="docutils literal"><span class="pre">E[i]</span></code>. The
correct results are, of course, <code class="docutils literal"><span class="pre">a[i]=0.4</span></code> and <code class="docutils literal"><span class="pre">E[i]=0.9*(i+1)</span></code>
but we will pretend that we do not know this.</p>
<p>Next we need code for the fit function. We assume that we know
that a sum of exponentials is appropriate, and therefore we define the following
Python function to represent the relationship between <code class="docutils literal"><span class="pre">x</span></code> and <code class="docutils literal"><span class="pre">y</span></code> in
our fit:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>         <span class="c"># function used to fit x, y data</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">p</span><span class="p">[</span><span class="s">&#39;a&#39;</span><span class="p">]</span>       <span class="c"># array of a[i]s</span>
    <span class="n">E</span> <span class="o">=</span> <span class="n">p</span><span class="p">[</span><span class="s">&#39;E&#39;</span><span class="p">]</span>       <span class="c"># array of E[i]s</span>
    <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">ai</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">Ei</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">ai</span><span class="p">,</span> <span class="n">Ei</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">E</span><span class="p">))</span>
</pre></div>
</div>
<p>The fit parameters, <code class="docutils literal"><span class="pre">a[i]</span></code> and <code class="docutils literal"><span class="pre">E[i]</span></code>, are stored in a
dictionary, using labels <code class="docutils literal"><span class="pre">a</span></code> and <code class="docutils literal"><span class="pre">E</span></code> to access them. These parameters
are varied in the fit to find the best-fit values <code class="docutils literal"><span class="pre">p=p_fit</span></code> for which
<code class="docutils literal"><span class="pre">f(x,</span> <span class="pre">p_fit)</span></code> most closely approximates the <code class="docutils literal"><span class="pre">y</span></code>s in our fit data. The
number of exponentials included in the sum is specified implicitly in this
function, by the lengths of the <code class="docutils literal"><span class="pre">p['a']</span></code> and <code class="docutils literal"><span class="pre">p['E']</span></code> arrays.</p>
<p>Finally we need to define priors that encapsulate our <em>a priori</em> knowledge
about the fit-parameter values. In practice we almost always have <em>a priori</em>
knowledge about parameters; it is usually impossible to design a fit
function without some sense of the parameter sizes. Given such knowledge
it is important (usually essential) to include it in the fit. This is
done by designing priors for the fit, which are probability distributions
for each parameter that describe the <em>a priori</em> uncertainty in that
parameter. As discussed in the previous section, we use objects of type
<code class="xref py py-class docutils literal"><span class="pre">gvar.GVar</span></code> to describe (Gaussian) probability distributions.
Let&#8217;s assume that before the fit we suspect that each <code class="docutils literal"><span class="pre">a[i]</span></code> is of order
0.5±0.5, while <code class="docutils literal"><span class="pre">E[i]</span></code> is of order (1+i)±0.5. A prior
that represents this information is built using the following code:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">lsqfit</span>
<span class="kn">import</span> <span class="nn">gvar</span> <span class="kn">as</span> <span class="nn">gv</span>

<span class="k">def</span> <span class="nf">make_prior</span><span class="p">(</span><span class="n">nexp</span><span class="p">):</span>               <span class="c"># make priors for fit parameters</span>
    <span class="n">prior</span> <span class="o">=</span> <span class="n">gv</span><span class="o">.</span><span class="n">BufferDict</span><span class="p">()</span>         <span class="c"># prior -- any dictionary works</span>
    <span class="n">prior</span><span class="p">[</span><span class="s">&#39;a&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">gv</span><span class="o">.</span><span class="n">gvar</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nexp</span><span class="p">)]</span>
    <span class="n">prior</span><span class="p">[</span><span class="s">&#39;E&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">gv</span><span class="o">.</span><span class="n">gvar</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nexp</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">prior</span>
</pre></div>
</div>
<p>where <code class="docutils literal"><span class="pre">nexp</span></code> is the number of exponential terms that will be used (and
therefore the number of <code class="docutils literal"><span class="pre">a</span></code>s and <code class="docutils literal"><span class="pre">E</span></code>s). With <code class="docutils literal"><span class="pre">nexp=3</span></code>, for example,
one would then have:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">prior</span><span class="p">[</span><span class="s">&#39;a&#39;</span><span class="p">])</span>
<span class="go">[0.50(50) 0.50(50) 0.50(50)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">prior</span><span class="p">[</span><span class="s">&#39;E&#39;</span><span class="p">])</span>
<span class="go">[1.00(50), 2.00(50), 3.00(50)]</span>
</pre></div>
</div>
<p>We use dictionary-like class <code class="xref py py-class docutils literal"><span class="pre">gvar.BufferDict</span></code> for the prior because it
allows us to save the prior if we wish (using Python&#8217;s <code class="xref py py-mod docutils literal"><span class="pre">pickle</span></code> module).
If saving is unnecessary, <code class="xref py py-class docutils literal"><span class="pre">gvar.BufferDict</span></code> can be replaced by
<code class="docutils literal"><span class="pre">dict()</span></code> or most any other Python dictionary class.</p>
<p>With fit data, a fit function, and a prior for the fit parameters, we are
finally ready to do the fit, which is now easy:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">fit</span> <span class="o">=</span> <span class="n">lsqfit</span><span class="o">.</span><span class="n">nonlinear_fit</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">fcn</span><span class="o">=</span><span class="n">f</span><span class="p">,</span> <span class="n">prior</span><span class="o">=</span><span class="n">prior</span><span class="p">)</span>
</pre></div>
</div>
<p>So pulling together the entire code,
our complete Python program for making fake data and fitting it is:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">lsqfit</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">gvar</span> <span class="kn">as</span> <span class="nn">gv</span>

<span class="k">def</span> <span class="nf">f_exact</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">nexp</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>          <span class="c"># exact f(x)</span>
    <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="mf">0.4</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mf">0.9</span><span class="o">*</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nexp</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>                        <span class="c"># function used to fit x, y data</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">p</span><span class="p">[</span><span class="s">&#39;a&#39;</span><span class="p">]</span>                      <span class="c"># array of a[i]s</span>
    <span class="n">E</span> <span class="o">=</span> <span class="n">p</span><span class="p">[</span><span class="s">&#39;E&#39;</span><span class="p">]</span>                      <span class="c"># array of E[i]s</span>
    <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">ai</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">Ei</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">ai</span><span class="p">,</span> <span class="n">Ei</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">E</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">make_data</span><span class="p">(</span><span class="n">nexp</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span> <span class="c"># make x, y fit data</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span><span class="mf">2.</span><span class="p">,</span><span class="mf">3.</span><span class="p">,</span><span class="mf">4.</span><span class="p">,</span><span class="mf">5.</span><span class="p">,</span><span class="mf">6.</span><span class="p">,</span><span class="mf">7.</span><span class="p">,</span><span class="mf">8.</span><span class="p">,</span><span class="mf">9.</span><span class="p">,</span><span class="mf">10.</span><span class="p">,</span><span class="mf">12.</span><span class="p">,</span><span class="mf">14.</span><span class="p">,</span><span class="mf">16.</span><span class="p">,</span><span class="mf">18.</span><span class="p">,</span><span class="mf">20.</span><span class="p">])</span>
    <span class="n">cr</span> <span class="o">=</span> <span class="n">gv</span><span class="o">.</span><span class="n">gvar</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">eps</span><span class="p">)</span>
    <span class="n">c</span> <span class="o">=</span> <span class="p">[</span><span class="n">gv</span><span class="o">.</span><span class="n">gvar</span><span class="p">(</span><span class="n">cr</span><span class="p">(),</span> <span class="n">eps</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)]</span>
    <span class="n">x_xmax</span> <span class="o">=</span> <span class="n">x</span><span class="o">/</span><span class="nb">max</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">noise</span> <span class="o">=</span> <span class="mi">1</span><span class="o">+</span> <span class="nb">sum</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">*</span> <span class="n">x_xmax</span> <span class="o">**</span> <span class="n">n</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">))</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">f_exact</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">nexp</span><span class="p">)</span> <span class="o">*</span> <span class="n">noise</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span>

<span class="k">def</span> <span class="nf">make_prior</span><span class="p">(</span><span class="n">nexp</span><span class="p">):</span>               <span class="c"># make priors for fit parameters</span>
    <span class="n">prior</span> <span class="o">=</span> <span class="n">gv</span><span class="o">.</span><span class="n">BufferDict</span><span class="p">()</span>         <span class="c"># prior -- any dictionary works</span>
    <span class="n">prior</span><span class="p">[</span><span class="s">&#39;a&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">gv</span><span class="o">.</span><span class="n">gvar</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nexp</span><span class="p">)]</span>
    <span class="n">prior</span><span class="p">[</span><span class="s">&#39;E&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">gv</span><span class="o">.</span><span class="n">gvar</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nexp</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">prior</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">gv</span><span class="o">.</span><span class="n">ranseed</span><span class="p">([</span><span class="mi">2009</span><span class="p">,</span> <span class="mi">2010</span><span class="p">,</span> <span class="mi">2011</span><span class="p">,</span> <span class="mi">2012</span><span class="p">])</span> <span class="c"># initialize random numbers (opt.)</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_data</span><span class="p">()</span>              <span class="c"># make fit data</span>
    <span class="n">p0</span> <span class="o">=</span> <span class="bp">None</span>                       <span class="c"># make larger fits go faster (opt.)</span>
    <span class="k">for</span> <span class="n">nexp</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">20</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="s">&#39;************************************* nexp =&#39;</span><span class="p">,</span> <span class="n">nexp</span><span class="p">)</span>
        <span class="n">prior</span> <span class="o">=</span> <span class="n">make_prior</span><span class="p">(</span><span class="n">nexp</span><span class="p">)</span>
        <span class="n">fit</span> <span class="o">=</span> <span class="n">lsqfit</span><span class="o">.</span><span class="n">nonlinear_fit</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">fcn</span><span class="o">=</span><span class="n">f</span><span class="p">,</span> <span class="n">prior</span><span class="o">=</span><span class="n">prior</span><span class="p">,</span> <span class="n">p0</span><span class="o">=</span><span class="n">p0</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>                  <span class="c"># print the fit results</span>
        <span class="n">E</span> <span class="o">=</span> <span class="n">fit</span><span class="o">.</span><span class="n">p</span><span class="p">[</span><span class="s">&#39;E&#39;</span><span class="p">]</span>              <span class="c"># best-fit parameters</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">fit</span><span class="o">.</span><span class="n">p</span><span class="p">[</span><span class="s">&#39;a&#39;</span><span class="p">]</span>
        <span class="k">print</span><span class="p">(</span><span class="s">&#39;E1/E0 =&#39;</span><span class="p">,</span> <span class="n">E</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">E</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s">&#39;  E2/E0 =&#39;</span><span class="p">,</span> <span class="n">E</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">/</span> <span class="n">E</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">print</span><span class="p">(</span><span class="s">&#39;a1/a0 =&#39;</span><span class="p">,</span> <span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s">&#39;  a2/a0 =&#39;</span><span class="p">,</span> <span class="n">a</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">/</span> <span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">print</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">fit</span><span class="o">.</span><span class="n">chi2</span> <span class="o">/</span> <span class="n">fit</span><span class="o">.</span><span class="n">dof</span> <span class="o">&lt;</span> <span class="mf">1.</span><span class="p">:</span>
            <span class="n">p0</span> <span class="o">=</span> <span class="n">fit</span><span class="o">.</span><span class="n">pmean</span>          <span class="c"># starting point for next fit (opt.)</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
<p>We are not sure <em>a priori</em> how many exponentials are needed to fit our
data. Given that there are only fifteen <code class="docutils literal"><span class="pre">y</span></code>s, and these are noisy, there
may only be information in the data about the first few terms. Consequently
we write our code to try fitting with each of <code class="docutils literal"><span class="pre">nexp=3,4,5..19</span></code> terms.
(The pieces of the code involving <code class="docutils literal"><span class="pre">p0</span></code> are optional; they make the
more complicated fits go about 30 times faster since the output from one
fit is used as the starting point for the next fit &#8212; see the discussion
of the <code class="docutils literal"><span class="pre">p0</span></code> parameter for <a class="reference internal" href="lsqfit.html#lsqfit.nonlinear_fit" title="lsqfit.nonlinear_fit"><code class="xref py py-class docutils literal"><span class="pre">lsqfit.nonlinear_fit</span></code></a>.) Running
this code produces the following output, which is reproduced here in some
detail in order to illustrate a variety of features:</p>
<div class="highlight-python"><div class="highlight"><pre>************************************* nexp = 3
Least Square Fit:
  chi2/dof [dof] = 6.3e+02 [15]    Q = 0    logGBF = -4465

Parameters:
            a 0   0.0288 (11)     [  0.50 (50) ]  
              1   0.0354 (13)     [  0.50 (50) ]  
              2   0.0779 (30)     [  0.50 (50) ]  
            E 0   1.0107 (24)     [  1.00 (50) ]  
              1   2.0200 (27)     [  2.00 (50) ]  
              2   3.6643 (33)     [  3.00 (50) ]  *

Settings:
  svdcut/n = 1e-15/2    reltol/abstol = 0.0001/0    (itns/time = 30/0.0)

E1/E0 = 1.9986(24)   E2/E0 = 3.6255(62)
a1/a0 = 1.23130(47)   a2/a0 = 2.7070(13)

************************************* nexp = 4
Least Square Fit:
  chi2/dof [dof] = 0.57 [15]    Q = 0.9    logGBF = 220.04

Parameters:
            a 0    0.4018 (40)      [  0.50 (50) ]  
              1    0.4055 (42)      [  0.50 (50) ]  
              2    0.4952 (76)      [  0.50 (50) ]  
              3     1.124 (12)      [  0.50 (50) ]  *
            E 0   0.90037 (51)      [  1.00 (50) ]  
              1    1.8023 (13)      [  2.00 (50) ]  
              2    2.7731 (90)      [  3.00 (50) ]  
              3     4.383 (21)      [  4.00 (50) ]  

Settings:
  svdcut/n = 1e-15/2    reltol/abstol = 0.0001/0    (itns/time = 233/0.1)

E1/E0 = 2.0018(12)   E2/E0 = 3.0800(98)
a1/a0 = 1.0094(30)   a2/a0 = 1.233(14)

************************************* nexp = 5
Least Square Fit:
  chi2/dof [dof] = 0.45 [15]    Q = 0.97    logGBF = 220.84

Parameters:
            a 0    0.4018 (40)      [  0.50 (50) ]  
              1    0.4049 (44)      [  0.50 (50) ]  
              2     0.478 (26)      [  0.50 (50) ]  
              3      0.63 (28)      [  0.50 (50) ]  
              4      0.62 (35)      [  0.50 (50) ]  
            E 0   0.90036 (51)      [  1.00 (50) ]  
              1    1.8019 (15)      [  2.00 (50) ]  
              2     2.759 (22)      [  3.00 (50) ]  
              3      4.09 (26)      [  4.00 (50) ]  
              4      4.95 (48)      [  5.00 (50) ]  

Settings:
  svdcut/n = 1e-15/2    reltol/abstol = 0.0001/0    (itns/time = 6/0.0)

E1/E0 = 2.0013(14)   E2/E0 = 3.065(24)
a1/a0 = 1.0075(42)   a2/a0 = 1.189(63)

************************************* nexp = 6
Least Square Fit:
  chi2/dof [dof] = 0.45 [15]    Q = 0.97    logGBF = 220.7

Parameters:
            a 0    0.4018 (40)      [  0.50 (50) ]  
              1    0.4041 (47)      [  0.50 (50) ]  
              2     0.461 (41)      [  0.50 (50) ]  
              3      0.60 (24)      [  0.50 (50) ]  
              4      0.47 (37)      [  0.50 (50) ]  
              5      0.45 (46)      [  0.50 (50) ]  
            E 0   0.90035 (51)      [  1.00 (50) ]  
              1    1.8015 (17)      [  2.00 (50) ]  
              2     2.746 (34)      [  3.00 (50) ]  
              3      3.98 (32)      [  4.00 (50) ]  
              4      4.96 (49)      [  5.00 (50) ]  
              5      6.01 (50)      [  6.00 (50) ]  

Settings:
  svdcut/n = 1e-15/2    reltol/abstol = 0.0001/0    (itns/time = 6/0.0)

E1/E0 = 2.0008(17)   E2/E0 = 3.049(37)
a1/a0 = 1.0055(56)   a2/a0 = 1.15(10)

************************************* nexp = 7
Least Square Fit:
  chi2/dof [dof] = 0.45 [15]    Q = 0.96    logGBF = 220.6

Parameters:
            a 0    0.4018 (40)      [  0.50 (50) ]  
              1    0.4036 (48)      [  0.50 (50) ]  
              2     0.452 (47)      [  0.50 (50) ]  
              3      0.60 (22)      [  0.50 (50) ]  
              4      0.42 (37)      [  0.50 (50) ]  
              5      0.42 (46)      [  0.50 (50) ]  
              6      0.46 (49)      [  0.50 (50) ]  
            E 0   0.90035 (51)      [  1.00 (50) ]  
              1    1.8012 (18)      [  2.00 (50) ]  
              2     2.739 (39)      [  3.00 (50) ]  
              3      3.94 (33)      [  4.00 (50) ]  
              4      4.96 (49)      [  5.00 (50) ]  
              5      6.02 (50)      [  6.00 (50) ]  
              6      7.02 (50)      [  7.00 (50) ]  

Settings:
  svdcut/n = 1e-15/2    reltol/abstol = 0.0001/0    (itns/time = 6/0.0)

E1/E0 = 2.0006(18)   E2/E0 = 3.042(43)
a1/a0 = 1.0045(63)   a2/a0 = 1.13(12)
                                    .                                    
                                    .                                    
                                    .                                    

************************************* nexp = 19
Least Square Fit:
  chi2/dof [dof] = 0.46 [15]    Q = 0.96    logGBF = 220.52

Parameters:
            a 0    0.4018 (40)      [  0.50 (50) ]  
              1    0.4033 (49)      [  0.50 (50) ]  
              2     0.447 (51)      [  0.50 (50) ]  
              3      0.60 (21)      [  0.50 (50) ]  
              4      0.38 (37)      [  0.50 (50) ]  
              5      0.40 (46)      [  0.50 (50) ]  
              6      0.45 (49)      [  0.50 (50) ]  
              7      0.48 (50)      [  0.50 (50) ]  
              8      0.49 (50)      [  0.50 (50) ]  
              9      0.50 (50)      [  0.50 (50) ]  
             10      0.50 (50)      [  0.50 (50) ]  
             11      0.50 (50)      [  0.50 (50) ]  
             12      0.50 (50)      [  0.50 (50) ]  
             13      0.50 (50)      [  0.50 (50) ]  
             14      0.50 (50)      [  0.50 (50) ]  
             15      0.50 (50)      [  0.50 (50) ]  
             16      0.50 (50)      [  0.50 (50) ]  
             17      0.50 (50)      [  0.50 (50) ]  
             18      0.50 (50)      [  0.50 (50) ]  
            E 0   0.90035 (51)      [  1.00 (50) ]  
              1    1.8011 (19)      [  2.00 (50) ]  
              2     2.734 (42)      [  3.00 (50) ]  
              3      3.91 (33)      [  4.00 (50) ]  
              4      4.97 (49)      [  5.00 (50) ]  
              5      6.02 (50)      [  6.00 (50) ]  
              6      7.02 (50)      [  7.00 (50) ]  
              7      8.01 (50)      [  8.00 (50) ]  
              8      9.00 (50)      [  9.00 (50) ]  
              9     10.00 (50)      [ 10.00 (50) ]  
             10     11.00 (50)      [ 11.00 (50) ]  
             11     12.00 (50)      [ 12.00 (50) ]  
             12     13.00 (50)      [ 13.00 (50) ]  
             13     14.00 (50)      [ 14.00 (50) ]  
             14     15.00 (50)      [ 15.00 (50) ]  
             15     16.00 (50)      [ 16.00 (50) ]  
             16     17.00 (50)      [ 17.00 (50) ]  
             17     18.00 (50)      [ 18.00 (50) ]  
             18     19.00 (50)      [ 19.00 (50) ]  

Settings:
  svdcut/n = 1e-15/2    reltol/abstol = 0.0001/0    (itns/time = 1/0.0)

E1/E0 = 2.0004(19)   E2/E0 = 3.036(47)
a1/a0 = 1.0038(67)   a2/a0 = 1.11(13)

--------------------- fit with extra information
</pre></div>
</div>
<p>There are several things to notice here:</p>
<blockquote>
<div><ul>
<li><p class="first">Clearly three exponentials (<code class="docutils literal"><span class="pre">nexp=3</span></code>) is not enough. The <code class="docutils literal"><span class="pre">chi**2</span></code>
per degree of freedom (<code class="docutils literal"><span class="pre">chi2/dof</span></code>) is much larger than one. The
<code class="docutils literal"><span class="pre">chi**2</span></code> improves significantly for <code class="docutils literal"><span class="pre">nexp=4</span></code> exponentials and by
<code class="docutils literal"><span class="pre">nexp=6</span></code> the fit is as good as it is going to get &#8212; there is
essentially no change when further exponentials are added.</p>
</li>
<li><p class="first">The best-fit values for each parameter are listed for each of the
fits, together with the prior values (in brackets, on the right).
Values for each <code class="docutils literal"><span class="pre">a[i]</span></code> and <code class="docutils literal"><span class="pre">E[i]</span></code> are listed in order, starting at
the points indicated by the labels <code class="docutils literal"><span class="pre">a</span></code> and <code class="docutils literal"><span class="pre">E</span></code>. Asterisks are
printed at the end of the line if the mean best-fit value differs from
the prior&#8217;s mean by more than one standard deviation; the number
of asterisks, up to a maximum of 5, indicates how many standard
deviations the difference is. Differences of one or two standard
deviations are not uncommon; larger differences could indicate a
problem with the prior or the fit.</p>
<p>Once the fit converges, the best-fit values for the various parameters
agree well &#8212; that is to within their errors, approximately &#8212; with
the exact values, which we know since we are using fake data. For
example, <code class="docutils literal"><span class="pre">a</span></code> and <code class="docutils literal"><span class="pre">E</span></code> for the first exponential are 0.402(4)
and 0.9003(5), respectively, from the fit where the exact answers
are 0.4 and 0.9; and we get 0.45(5) and 2.73(4) for
the third exponential where the exact values are 0.4 and 2.7.</p>
</li>
<li><p class="first">Note in the <code class="docutils literal"><span class="pre">nexp=7</span></code> fit how the means and standard deviations for
the parameters governing the seventh (and last) exponential are almost
identical to the values in the corresponding priors: 0.46(49) from
the fit for <code class="docutils literal"><span class="pre">a</span></code> and 7.0(5) for <code class="docutils literal"><span class="pre">E</span></code>. This tells us that our fit
data has little or no information to add to what we knew <em>a priori</em>
about these parameters &#8212; there isn&#8217;t enough data and what we have
isn&#8217;t accurate enough.</p>
<p>This situation is truer still of further terms as they are added in
the <code class="docutils literal"><span class="pre">nexp=8</span></code> and later fits. This is why the fit results stop
changing once we have <code class="docutils literal"><span class="pre">nexp=6</span></code> exponentials. There is no point in
including further exponentials, beyond the need to verify that the fit
has indeed converged.</p>
</li>
<li><p class="first">The last fit includes <code class="docutils literal"><span class="pre">nexp=19</span></code> exponentials and therefore has 38
parameters. This is in a fit to 15 <code class="docutils literal"><span class="pre">y</span></code>s. Old-fashioned fits, without
priors, are impossible when the number of parameters exceeds the number
of data points. That is clearly not the case here, where the number of
terms and parameters can be made arbitrarily large, eventually (after
<code class="docutils literal"><span class="pre">nexp=6</span></code> terms) with no effect at all on the results.</p>
<p>The reason is that the prior that we include for each new parameter
is, in effect, a new piece of data (the mean and standard deviation of
the <em>a priori</em> expectation for that parameter); it leads to a new term
in the <code class="docutils literal"><span class="pre">chi**2</span></code> function. We are fitting both the data and our <em>a
priori</em> expectations for the parameters. So in the <code class="docutils literal"><span class="pre">nexp=19</span></code> fit,
for example, we actually have 53 pieces of data to fit: the 15 <code class="docutils literal"><span class="pre">y</span></code>s
plus the 38 prior values for the 38 parameters.</p>
<p>The effective number of degrees of freedom (<code class="docutils literal"><span class="pre">dof</span></code> in the output
above) is the number of pieces of data minus the number of fit
parameters, or 53-38=15 in this last case. With priors for every
parameter, the number of degrees of freedom is always equal to the
number of <code class="docutils literal"><span class="pre">y</span></code>s, irrespective of how many fit parameters there are.</p>
</li>
<li><p class="first">The Gaussian Bayes Factor (whose logarithm is
<code class="docutils literal"><span class="pre">logGBF</span></code> in the output) is a measure of the likelihood that the actual
data being fit could have come from a theory with the prior and
fit function used in the
fit. The larger this number, the more likely it is that prior/fit-function
and data
could be related. Here it grows dramatically from the first fit
(<code class="docutils literal"><span class="pre">nexp=3</span></code>) but then more-or-less stops changing around <code class="docutils literal"><span class="pre">nexp=5</span></code>. The
implication is that this data is much more likely to have come from a
theory with <code class="docutils literal"><span class="pre">nexp&gt;=5</span></code> than with <code class="docutils literal"><span class="pre">nexp=3</span></code> (which we know to be the
actual case).</p>
</li>
<li><p class="first">In the code, results for each fit are captured in a Python object
<code class="docutils literal"><span class="pre">fit</span></code>, which is of type <a class="reference internal" href="lsqfit.html#lsqfit.nonlinear_fit" title="lsqfit.nonlinear_fit"><code class="xref py py-class docutils literal"><span class="pre">lsqfit.nonlinear_fit</span></code></a>. A summary of the
fit information is obtained by printing <code class="docutils literal"><span class="pre">fit</span></code>. Also the best-fit
results for each fit parameter can be accessed through <code class="docutils literal"><span class="pre">fit.p</span></code>, as is
done here to calculate various ratios of parameters.</p>
<p>The errors in these last calculations automatically account for any
correlations in the statistical errors for different parameters. This
is obvious in the ratio <code class="docutils literal"><span class="pre">a1/a0</span></code>, which would be 1.004(16) if
there was no statistical correlation between our estimates for <code class="docutils literal"><span class="pre">a1</span></code>
and <code class="docutils literal"><span class="pre">a0</span></code>, but in fact is 1.004(7) in this fit. The (positive)
correlation is evident in the covariance matrix:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">gv</span><span class="o">.</span><span class="n">evalcov</span><span class="p">([</span><span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">]]))</span>
<span class="go">[[  1.61726195e-05   1.65492001e-05]</span>
<span class="go">[  1.65492001e-05   2.41547633e-05]]</span>
</pre></div>
</div>
</li>
</ul>
</div></blockquote>
<p>Finally we inspect the fit&#8217;s quality point by point. The input data are
compared with results from the fit function, evaluated with the best-fit
parameters, in the following table (obtained in the code by printing the
output from <code class="docutils literal"><span class="pre">fit.format(maxline=True)</span></code>):</p>
<div class="highlight-python"><div class="highlight"><pre>Fit:
     x[k]               y[k]          f(x[k],p)
-----------------------------------------------
        1        0.2752 (27)        0.2752 (20)
        2       0.07951 (80)       0.07952 (58)
        3       0.02891 (29)       0.02892 (21)
        4       0.01127 (11)      0.011272 (83)
        5      0.004502 (46)      0.004506 (34)
        6      0.001817 (19)      0.001819 (14)
        7     0.0007362 (79)     0.0007375 (57)
        8     0.0002987 (33)     0.0002994 (24)
        9     0.0001213 (14)    0.00012163 (99)
       10    0.00004926 (57)    0.00004943 (41)
       12       8.13(10)e-06      8.164(72)e-06
       14      1.342(19)e-06      1.348(13)e-06
       16      2.217(37)e-07      2.227(23)e-07
       18      3.661(85)e-08      3.679(40)e-08
       20       6.24(61)e-09      6.078(71)e-09
</pre></div>
</div>
<p>The fit is excellent over the entire eight orders of magnitude. This
information is presented again in the following plot, which shows the ratio
<code class="docutils literal"><span class="pre">y/f(x,p)</span></code>, as a function of <code class="docutils literal"><span class="pre">x</span></code>, using the best-fit parameters <code class="docutils literal"><span class="pre">p</span></code>.
The correct result for this ratio, of course, is one. The smooth variation
in the data &#8212; smooth compared with the size of the statistical-error bars
&#8212; is an indication of the statistical correlations between individual
<code class="docutils literal"><span class="pre">y</span></code>s.</p>
<a class="reference internal image-reference" href="_images/fig1.png"><img alt="_images/fig1.png" src="_images/fig1.png" style="width: 80%;" /></a>
<p>This particular plot was made using the <code class="xref py py-mod docutils literal"><span class="pre">matplotlib</span></code> module, with the
following code added to the end of <code class="docutils literal"><span class="pre">main()</span></code> (outside the loop):</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">pylab</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="n">ratio</span> <span class="o">=</span> <span class="n">y</span> <span class="o">/</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">fit</span><span class="o">.</span><span class="n">pmean</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">21</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">&#39;y/f(x,p)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">errorbar</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">gv</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">ratio</span><span class="p">),</span> <span class="n">yerr</span><span class="o">=</span><span class="n">gv</span><span class="o">.</span><span class="n">sdev</span><span class="p">(</span><span class="n">ratio</span><span class="p">),</span> <span class="n">fmt</span><span class="o">=</span><span class="s">&#39;ob&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">21.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p><strong>Making Fake Data:</strong> Function <code class="docutils literal"><span class="pre">make_data()</span></code> creates a list of <code class="docutils literal"><span class="pre">x</span></code> values,
evaluates the underlying function, <code class="docutils literal"><span class="pre">f_exact(x)</span></code>, for those values,
and then adds random noise to the results to create the <code class="docutils literal"><span class="pre">y</span></code> array
of fit data: <code class="docutils literal"><span class="pre">y</span> <span class="pre">=</span> <span class="pre">f_exact(x)</span> <span class="pre">*</span> <span class="pre">noise</span></code> where</p>
<div class="highlight-python"><div class="highlight"><pre>noise = 1 + sum_n=0..99 c[n] * (x/x_max) ** n
</pre></div>
</div>
<p>Here the <code class="docutils literal"><span class="pre">c[n]</span></code> are random coefficients generated using the following code:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">cr</span> <span class="o">=</span> <span class="n">gv</span><span class="o">.</span><span class="n">gvar</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">eps</span><span class="p">)</span>
<span class="n">c</span> <span class="o">=</span> <span class="p">[</span><span class="n">gv</span><span class="o">.</span><span class="n">gvar</span><span class="p">(</span><span class="n">cr</span><span class="p">(),</span> <span class="n">eps</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)]</span>
</pre></div>
</div>
<p>Gaussian variable <code class="docutils literal"><span class="pre">cr</span></code> represents a Gaussian distribution with mean
0.0 and width 0.01, which we use here as a random number generator:
<code class="docutils literal"><span class="pre">cr()</span></code> is a number drawn randomly from the distribution represented by
<code class="docutils literal"><span class="pre">cr</span></code>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">cr</span><span class="p">)</span>
<span class="go">0.000(10)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">cr</span><span class="p">())</span>
<span class="go">0.00452180208286</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">cr</span><span class="p">())</span>
<span class="go">-0.00731564589737</span>
</pre></div>
</div>
<p>We use <code class="docutils literal"><span class="pre">cr()</span></code> to generate mean values for the Gaussian distributions
represented by the <code class="docutils literal"><span class="pre">c[n]</span></code>s, each of which has width 0.01. The resulting
<code class="docutils literal"><span class="pre">y</span></code>s fluctuate around the corresponding values of <code class="docutils literal"><span class="pre">f_exact(x)</span></code>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">y</span><span class="o">-</span><span class="n">f_exact</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="go">[0.0011(27) 0.00029(80) ... ]</span>
</pre></div>
</div>
<p>The Gaussian variables <code class="docutils literal"><span class="pre">y[i]</span></code> together with the numbers <code class="docutils literal"><span class="pre">x[i]</span></code> comprise
our fake data.</p>
</div>
<div class="section" id="chained-fits">
<h2>Chained Fits<a class="headerlink" href="#chained-fits" title="Permalink to this headline">¶</a></h2>
<p>The priors in a fit represent knowledge that we have about the parameters
before we do the fit. This knowledge might come from theoretical considerations
or experiment. Or it might come from another fit. Imagine that we want to add
new information to that extracted from the fit in the previous section.
For example, we might learn from some other source that the ratio of
amplitudes <code class="docutils literal"><span class="pre">a[1]/a[0]</span></code> equals 1±1e-5. The challenge is to combine
this new information with information extracted from the fit above without rerunning
that fit. (We assume it is not possible to rerun the first fit, because, say,
the input data for that fit has been lost or is unavailable.)</p>
<p>We can combine the new data with the old fit results by creating a new
fit using the best-fit parameters, <code class="docutils literal"><span class="pre">fit.p</span></code>, from the old fit as the
priors for the new fit. To try this out, we add the following code
onto the end of the <code class="docutils literal"><span class="pre">main()</span></code> subroutine in the previous section:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">ratio</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>                       <span class="c"># new fit function</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">p</span><span class="p">[</span><span class="s">&#39;a&#39;</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">prior</span> <span class="o">=</span> <span class="n">fit</span><span class="o">.</span><span class="n">p</span>                       <span class="c"># prior = best-fit parameters from 1st fit</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">gv</span><span class="o">.</span><span class="n">gvar</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">)</span>             <span class="c"># new data for the ratio</span>

<span class="n">newfit</span> <span class="o">=</span> <span class="n">lsqfit</span><span class="o">.</span><span class="n">nonlinear_fit</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">fcn</span><span class="o">=</span><span class="n">ratio</span><span class="p">,</span> <span class="n">prior</span><span class="o">=</span><span class="n">prior</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">newfit</span><span class="p">)</span>
</pre></div>
</div>
<p>The result of the new fit (to one piece of new data) is:</p>
<div class="highlight-python"><div class="highlight"><pre>Least Square Fit:
  chi2/dof [dof] = 0.32 [1]    Q = 0.57    logGBF = 3.9303

Parameters:
            a 0    0.4018 (40)      [  0.4018 (40) ]  
              1    0.4018 (40)      [  0.4033 (49) ]  
              2     0.421 (20)      [   0.447 (51) ]  
              3      0.53 (17)      [    0.60 (21) ]  
              4      0.46 (34)      [    0.38 (37) ]  
              5      0.50 (42)      [    0.40 (46) ]  
              6      0.50 (48)      [    0.45 (49) ]  
              7      0.50 (50)      [    0.48 (50) ]  
              8      0.50 (50)      [    0.49 (50) ]  
              9      0.50 (50)      [    0.50 (50) ]  
             10      0.50 (50)      [    0.50 (50) ]  
             11      0.50 (50)      [    0.50 (50) ]  
             12      0.50 (50)      [    0.50 (50) ]  
             13      0.50 (50)      [    0.50 (50) ]  
             14      0.50 (50)      [    0.50 (50) ]  
             15      0.50 (50)      [    0.50 (50) ]  
             16      0.50 (50)      [    0.50 (50) ]  
             17      0.50 (50)      [    0.50 (50) ]  
             18      0.50 (50)      [    0.50 (50) ]  
            E 0   0.90030 (51)      [ 0.90035 (51) ]  
              1   1.80007 (67)      [  1.8011 (19) ]  
              2     2.711 (12)      [   2.734 (42) ]  
              3      3.76 (18)      [    3.91 (33) ]  
              4      5.02 (48)      [    4.97 (49) ]  
              5      6.00 (50)      [    6.02 (50) ]  
              6      7.00 (50)      [    7.02 (50) ]  
              7      8.00 (50)      [    8.01 (50) ]  
              8      9.00 (50)      [    9.00 (50) ]  
              9     10.00 (50)      [   10.00 (50) ]  
             10     11.00 (50)      [   11.00 (50) ]  
             11     12.00 (50)      [   12.00 (50) ]  
             12     13.00 (50)      [   13.00 (50) ]  
             13     14.00 (50)      [   14.00 (50) ]  
             14     15.00 (50)      [   15.00 (50) ]  
             15     16.00 (50)      [   16.00 (50) ]  
             16     17.00 (50)      [   17.00 (50) ]  
             17     18.00 (50)      [   18.00 (50) ]  
             18     19.00 (50)      [   19.00 (50) ]  

Settings:
  svdcut/n = 1e-15/0    reltol/abstol = 0.0001/0    (itns/time = 2/0.0)
</pre></div>
</div>
<p>Parameters <code class="docutils literal"><span class="pre">a[0]</span></code> and <code class="docutils literal"><span class="pre">E[0]</span></code> are essentially unchanged by the new
information, but <code class="docutils literal"><span class="pre">a[i]</span></code> and <code class="docutils literal"><span class="pre">E[i]</span></code> are more precise for <code class="docutils literal"><span class="pre">i=1</span></code>, <code class="docutils literal"><span class="pre">2</span></code>
and <code class="docutils literal"><span class="pre">3</span></code>, as is <code class="docutils literal"><span class="pre">a[1]/a[0]</span></code>, of course.
It might seem odd that <code class="docutils literal"><span class="pre">E[1]</span></code>, for example, is changed at
all, since the fit function, <code class="docutils literal"><span class="pre">ratio(p)</span></code>, makes no mention of it. This
is not surprising, however, since <code class="docutils literal"><span class="pre">ratio(p)</span></code> does depend upon <code class="docutils literal"><span class="pre">a[1]</span></code>,
and <code class="docutils literal"><span class="pre">a[1]</span></code> is strongly correlated with <code class="docutils literal"><span class="pre">E[1]</span></code> through the prior. It
is important to include all parameters from the first fit as
parameters in the new fit in order to capture the impact of the new
information on parameters correlated with <code class="docutils literal"><span class="pre">a[1]/a[0]</span></code>.</p>
<p>It would have been easy to change the fit code in the previous section to
incorporate the new information about <code class="docutils literal"><span class="pre">a[1]/a[0]</span></code>. The approach presented
here is numerically equivalent to that approach
insofar as the <code class="docutils literal"><span class="pre">chi**2</span></code> function for the
original fit can be well approximated by a quadratic function
in the fit parameters &#8212; that is, insofar as
<code class="docutils literal"><span class="pre">exp(-chi**2/2)</span></code> is well approximated
by a Gaussian distribution in the parameters, as
specified by the best-fit means and covariance matrix (in <code class="docutils literal"><span class="pre">fit.p</span></code>).
This is, of course, a fundamental assumption underlying the
use of <a class="reference internal" href="lsqfit.html#module-lsqfit" title="lsqfit: Nonlinear least squares fitting."><code class="xref py py-mod docutils literal"><span class="pre">lsqfit</span></code></a> in the first place.</p>
<p>Obviously, we can include further fits in order to incorporate more data. The
prior for each new fit is the best-fit output (<code class="docutils literal"><span class="pre">fit.p</span></code>) from the previous
fit. The output from the chain&#8217;s final fit is the cummulative  result of all
of these fits.</p>
<p>Finally note that this particular problem can be done much more
simply using a weighted average (<a class="reference internal" href="lsqfit.html#lsqfit.wavg" title="lsqfit.wavg"><code class="xref py py-func docutils literal"><span class="pre">lsqfit.wavg()</span></code></a>).
Adding the following code
onto the end of the <code class="docutils literal"><span class="pre">main()</span></code> subroutine in the previous section</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">fit</span><span class="o">.</span><span class="n">p</span><span class="p">[</span><span class="s">&#39;a1/a0&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fit</span><span class="o">.</span><span class="n">p</span><span class="p">[</span><span class="s">&#39;a&#39;</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">fit</span><span class="o">.</span><span class="n">p</span><span class="p">[</span><span class="s">&#39;a&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="n">new_data</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;a1/a0&#39;</span> <span class="p">:</span> <span class="n">gv</span><span class="o">.</span><span class="n">gvar</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mf">1e-5</span><span class="p">)}</span>
<span class="n">new_p</span> <span class="o">=</span> <span class="n">lsqfit</span><span class="o">.</span><span class="n">wavg</span><span class="p">([</span><span class="n">fit</span><span class="o">.</span><span class="n">p</span><span class="p">,</span> <span class="n">new_data</span><span class="p">])</span>

<span class="k">print</span><span class="p">(</span><span class="s">&#39;chi2/dof = </span><span class="si">%.2f</span><span class="se">\n</span><span class="s">&#39;</span> <span class="o">%</span> <span class="n">new_p</span><span class="o">.</span><span class="n">chi2</span> <span class="o">/</span> <span class="n">new_p</span><span class="o">.</span><span class="n">dof</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">&#39;E:&#39;</span><span class="p">,</span> <span class="n">new_p</span><span class="p">[</span><span class="s">&#39;E&#39;</span><span class="p">][:</span><span class="mi">4</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">&#39;a:&#39;</span><span class="p">,</span> <span class="n">new_p</span><span class="p">[</span><span class="s">&#39;a&#39;</span><span class="p">][:</span><span class="mi">4</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">&#39;a1/a0:&#39;</span><span class="p">,</span> <span class="n">new_p</span><span class="p">[</span><span class="s">&#39;a1/a0&#39;</span><span class="p">])</span>
</pre></div>
</div>
<p>gives the following output:</p>
<div class="highlight-python"><div class="highlight"><pre>chi2/dof = 0.32

E: [0.90030(51) 1.80007(67) 2.711(12) 3.76(18)]
a: [0.4018(39) 0.4018(40) 0.421(20) 0.53(17)]
a1/a0: 1.000000(10)
</pre></div>
</div>
<p>Here we do a weighted average of <code class="docutils literal"><span class="pre">a[1]/a[0]</span></code> from the
original fit (<code class="docutils literal"><span class="pre">fit.p['a1/a0']</span></code>) with our new piece of data
(<code class="docutils literal"><span class="pre">new_data['a1/a0']</span></code>). The dictionary <code class="docutils literal"><span class="pre">new_p</span></code> returned by
<a class="reference internal" href="lsqfit.html#lsqfit.wavg" title="lsqfit.wavg"><code class="xref py py-func docutils literal"><span class="pre">lsqfit.wavg()</span></code></a> has an entry for
every key in either <code class="docutils literal"><span class="pre">fit.p</span></code> or <code class="docutils literal"><span class="pre">new_data</span></code>. The weighted average for
<code class="docutils literal"><span class="pre">a[1]/a[0]</span></code> is in <code class="docutils literal"><span class="pre">new_data['a1/a0']</span></code>. New values for the
fit parameters, that take account of the new data, are stored in
<code class="docutils literal"><span class="pre">new_p['E']</span></code> and <code class="docutils literal"><span class="pre">new_p['a']</span></code>. The <code class="docutils literal"><span class="pre">E[i]</span></code> and <code class="docutils literal"><span class="pre">a[i]</span></code>
estimates differ from their values in <code class="docutils literal"><span class="pre">fit.p</span></code> since those parameters
are correlated with <code class="docutils literal"><span class="pre">a[1]/a[0]</span></code>. Consequently when the ratio
is shifted by new data, the  <code class="docutils literal"><span class="pre">E[i]</span></code> and <code class="docutils literal"><span class="pre">a[i]</span></code> are shifted as well.
The final results in <code class="docutils literal"><span class="pre">new_p</span></code>
are almost identical to what we obtained above; this is because
the errors are sufficiently small
that the ratio <code class="docutils literal"><span class="pre">a[1]/a[0]</span></code> is Gaussian.</p>
</div>
<div class="section" id="x-has-error-bars">
<h2><code class="docutils literal"><span class="pre">x</span></code> has Error Bars<a class="headerlink" href="#x-has-error-bars" title="Permalink to this headline">¶</a></h2>
<p>We now consider variations on our basic fit analysis (described in
<a class="reference internal" href="#basic-fits"><span>Basic Fits</span></a>).
The first variation concerns what to do when the independent variables, the
<code class="docutils literal"><span class="pre">x</span></code>s, have errors, as well as the <code class="docutils literal"><span class="pre">y</span></code>s. This is easily handled by
turning the <code class="docutils literal"><span class="pre">x</span></code>s into fit parameters, and otherwise dispensing
with independent variables.</p>
<p>To illustrate this, we modify the basic analysis code above.
First we need to add errors to the <code class="docutils literal"><span class="pre">x</span></code>s, which we do by
changing <code class="docutils literal"><span class="pre">make_data</span></code> so that each <code class="docutils literal"><span class="pre">x</span></code> has a random value within about
±0.001% of its original value and an error:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">make_data</span><span class="p">(</span><span class="n">nexp</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span> <span class="c"># make x, y fit data</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span><span class="mf">2.</span><span class="p">,</span><span class="mf">3.</span><span class="p">,</span><span class="mf">4.</span><span class="p">,</span><span class="mf">5.</span><span class="p">,</span><span class="mf">6.</span><span class="p">,</span><span class="mf">7.</span><span class="p">,</span><span class="mf">8.</span><span class="p">,</span><span class="mf">9.</span><span class="p">,</span><span class="mf">10.</span><span class="p">,</span><span class="mf">12.</span><span class="p">,</span><span class="mf">14.</span><span class="p">,</span><span class="mf">16.</span><span class="p">,</span><span class="mf">18.</span><span class="p">,</span><span class="mf">20.</span><span class="p">])</span>
    <span class="n">cr</span> <span class="o">=</span> <span class="n">gv</span><span class="o">.</span><span class="n">gvar</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">eps</span><span class="p">)</span>
    <span class="n">c</span> <span class="o">=</span> <span class="p">[</span><span class="n">gv</span><span class="o">.</span><span class="n">gvar</span><span class="p">(</span><span class="n">cr</span><span class="p">(),</span> <span class="n">eps</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)]</span>
    <span class="n">x_xmax</span> <span class="o">=</span> <span class="n">x</span><span class="o">/</span><span class="nb">max</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">noise</span> <span class="o">=</span> <span class="mi">1</span><span class="o">+</span> <span class="nb">sum</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">*</span> <span class="n">x_xmax</span> <span class="o">**</span> <span class="n">n</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">))</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">f_exact</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">nexp</span><span class="p">)</span> <span class="o">*</span> <span class="n">noise</span>            <span class="c"># noisy y[i]s</span>
    <span class="n">xfac</span> <span class="o">=</span> <span class="n">gv</span><span class="o">.</span><span class="n">gvar</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.00001</span><span class="p">)</span>    <span class="c"># Gaussian distrib&#39;n: 1±0.001%</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">xi</span> <span class="o">*</span> <span class="n">gv</span><span class="o">.</span><span class="n">gvar</span><span class="p">(</span><span class="n">xfac</span><span class="p">(),</span> <span class="n">xfac</span><span class="o">.</span><span class="n">sdev</span><span class="p">)</span> <span class="k">for</span> <span class="n">xi</span> <span class="ow">in</span> <span class="n">x</span><span class="p">])</span> <span class="c"># noisy x[i]s</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span>
</pre></div>
</div>
<p>Here <code class="xref py py-class docutils literal"><span class="pre">gvar.GVar</span></code> object <code class="docutils literal"><span class="pre">xfac</span></code> is used as a random number
generator: each time it is called, <code class="docutils literal"><span class="pre">xfac()</span></code> is a different random number
from the distribution with mean <code class="docutils literal"><span class="pre">xfac.mean</span></code> and standard deviation
<code class="docutils literal"><span class="pre">xfac.sdev</span></code> (that is, 1±0.00001). The main program is modified so
that the (now random) <code class="docutils literal"><span class="pre">x</span></code> array is treated as a fit parameter. The prior
for each <code class="docutils literal"><span class="pre">x</span></code> is, obviously, specified by the mean and standard deviation
of that <code class="docutils literal"><span class="pre">x</span></code>, which is read directly out of the array of <code class="docutils literal"><span class="pre">x</span></code>s produced
by <code class="docutils literal"><span class="pre">make_data()</span></code>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">make_prior</span><span class="p">(</span><span class="n">nexp</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>            <span class="c"># make priors for fit parameters</span>
    <span class="n">prior</span> <span class="o">=</span> <span class="n">gv</span><span class="o">.</span><span class="n">BufferDict</span><span class="p">()</span>         <span class="c"># prior -- any dictionary works</span>
    <span class="n">prior</span><span class="p">[</span><span class="s">&#39;a&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">gv</span><span class="o">.</span><span class="n">gvar</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nexp</span><span class="p">)]</span>
    <span class="n">prior</span><span class="p">[</span><span class="s">&#39;E&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">gv</span><span class="o">.</span><span class="n">gvar</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nexp</span><span class="p">)]</span>
    <span class="n">prior</span><span class="p">[</span><span class="s">&#39;x&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>                  <span class="c"># x now an array of parameters</span>
    <span class="k">return</span> <span class="n">prior</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">gv</span><span class="o">.</span><span class="n">ranseed</span><span class="p">([</span><span class="mi">2009</span><span class="p">,</span> <span class="mi">2010</span><span class="p">,</span> <span class="mi">2011</span><span class="p">,</span> <span class="mi">2012</span><span class="p">])</span> <span class="c"># initialize random numbers (opt.)</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_data</span><span class="p">()</span>              <span class="c"># make fit data</span>
    <span class="n">p0</span> <span class="o">=</span> <span class="bp">None</span>                       <span class="c"># make larger fits go faster (opt.)</span>
    <span class="k">for</span> <span class="n">nexp</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">20</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="s">&#39;************************************* nexp =&#39;</span><span class="p">,</span> <span class="n">nexp</span><span class="p">)</span>
        <span class="n">prior</span> <span class="o">=</span> <span class="n">make_prior</span><span class="p">(</span><span class="n">nexp</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="n">fit</span> <span class="o">=</span> <span class="n">lsqfit</span><span class="o">.</span><span class="n">nonlinear_fit</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">fcn</span><span class="o">=</span><span class="n">f</span><span class="p">,</span> <span class="n">prior</span><span class="o">=</span><span class="n">prior</span><span class="p">,</span> <span class="n">p0</span><span class="o">=</span><span class="n">p0</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>                  <span class="c"># print the fit results</span>
        <span class="n">E</span> <span class="o">=</span> <span class="n">fit</span><span class="o">.</span><span class="n">p</span><span class="p">[</span><span class="s">&#39;E&#39;</span><span class="p">]</span>              <span class="c"># best-fit parameters</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">fit</span><span class="o">.</span><span class="n">p</span><span class="p">[</span><span class="s">&#39;a&#39;</span><span class="p">]</span>
        <span class="k">print</span><span class="p">(</span><span class="s">&#39;E1/E0 =&#39;</span><span class="p">,</span> <span class="n">E</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">E</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s">&#39;  E2/E0 =&#39;</span><span class="p">,</span> <span class="n">E</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">/</span> <span class="n">E</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">print</span><span class="p">(</span><span class="s">&#39;a1/a0 =&#39;</span><span class="p">,</span> <span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s">&#39;  a2/a0 =&#39;</span><span class="p">,</span> <span class="n">a</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">/</span> <span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">print</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">fit</span><span class="o">.</span><span class="n">chi2</span><span class="o">/</span><span class="n">fit</span><span class="o">.</span><span class="n">dof</span><span class="o">&lt;</span><span class="mf">1.</span><span class="p">:</span>
            <span class="n">p0</span> <span class="o">=</span> <span class="n">fit</span><span class="o">.</span><span class="n">pmean</span>          <span class="c"># starting point for next fit (opt.)</span>
</pre></div>
</div>
<p>The fit data now consists of just the <code class="docutils literal"><span class="pre">y</span></code> array (<code class="docutils literal"><span class="pre">data=y</span></code>), and the
fit function loses its <code class="docutils literal"><span class="pre">x</span></code> argument and gets its <code class="docutils literal"><span class="pre">x</span></code> values from the
fit parameters <code class="docutils literal"><span class="pre">p</span></code> instead:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">p</span><span class="p">[</span><span class="s">&#39;a&#39;</span><span class="p">]</span>
    <span class="n">E</span> <span class="o">=</span> <span class="n">p</span><span class="p">[</span><span class="s">&#39;E&#39;</span><span class="p">]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">p</span><span class="p">[</span><span class="s">&#39;x&#39;</span><span class="p">]</span>
    <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">ai</span><span class="o">*</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">Ei</span><span class="o">*</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">ai</span><span class="p">,</span> <span class="n">Ei</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">E</span><span class="p">))</span>
</pre></div>
</div>
<p>Running the new code gives, for <code class="docutils literal"><span class="pre">nexp=6</span></code> terms:</p>
<div class="highlight-python"><div class="highlight"><pre>************************************* nexp = 6
Least Square Fit:
  chi2/dof [dof] = 0.54 [15]    Q = 0.92    logGBF = 198.93

Parameters:
            a 0      0.4025 (41)       [     0.50 (50) ]  
              1       0.429 (32)       [     0.50 (50) ]  
              2        0.58 (23)       [     0.50 (50) ]  
              3        0.40 (38)       [     0.50 (50) ]  
              4        0.42 (46)       [     0.50 (50) ]  
              5        0.46 (49)       [     0.50 (50) ]  
            E 0     0.90068 (60)       [     1.00 (50) ]  
              1       1.818 (20)       [     2.00 (50) ]  
              2        2.95 (28)       [     3.00 (50) ]  
              3        3.98 (49)       [     4.00 (50) ]  
              4        5.02 (50)       [     5.00 (50) ]  
              5        6.01 (50)       [     6.00 (50) ]  
            x 0    0.999997 (10)       [ 0.999997 (10) ]  
              1    1.999958 (20)       [ 1.999958 (20) ]  
              2    3.000014 (30)       [ 3.000013 (30) ]  
              3    4.000065 (36)       [ 4.000064 (40) ]  
              4    5.000047 (34)       [ 5.000069 (50) ]  
              5    6.000020 (39)       [ 5.999986 (60) ]  
              6    6.999988 (40)       [ 6.999942 (70) ]  
              7    7.999956 (42)       [ 7.999982 (80) ]  
              8    8.999934 (50)       [ 9.000054 (90) ]  *
              9    9.999923 (59)       [  9.99991 (10) ]  
             10   11.999929 (79)       [ 11.99982 (12) ]  
             11    13.99992 (11)       [ 13.99991 (14) ]  
             12    15.99992 (15)       [ 15.99998 (16) ]  
             13    18.00022 (18)       [ 18.00020 (18) ]  
             14    20.00016 (20)       [ 20.00016 (20) ]  

Settings:
  svdcut/n = 1e-15/2    reltol/abstol = 0.0001/0    (itns/time = 6/0.0)

E1/E0 = 2.018(22)   E2/E0 = 3.27(31)
a1/a0 = 1.065(77)   a2/a0 = 1.45(57)
</pre></div>
</div>
<p>This looks quite a bit like what we obtained before, except that now there
are 15 more parameters, one for each <code class="docutils literal"><span class="pre">x</span></code>, and also now all results are
a good deal less accurate. Note that one result from this analysis is new
values for the <code class="docutils literal"><span class="pre">x</span></code>s. In some cases (<em>e.g.</em>,  <code class="docutils literal"><span class="pre">x[7]</span></code>),
the errors on the <code class="docutils literal"><span class="pre">x</span></code> values have been
reduced &#8212; by information in the fit data.</p>
</div>
<div class="section" id="correlated-parameters-gaussian-bayes-factor">
<span id="correlated-parameters"></span><h2>Correlated Parameters; Gaussian Bayes Factor<a class="headerlink" href="#correlated-parameters-gaussian-bayes-factor" title="Permalink to this headline">¶</a></h2>
<p><code class="xref py py-class docutils literal"><span class="pre">gvar.GVar</span></code> objects are very useful for handling more complicated
priors, including situations where we know <em>a priori</em> of correlations
between parameters. Returning to the <a class="reference internal" href="#basic-fits"><span>Basic Fits</span></a> example above,
imagine a situation where we still have a ±0.5 uncertainty about the
value of any individual <code class="docutils literal"><span class="pre">E[i]</span></code>, but we know <em>a priori</em> that the
separations between adjacent <code class="docutils literal"><span class="pre">E[i]</span></code>s is 0.9±0.01. We want to
build the correlation between adjacent <code class="docutils literal"><span class="pre">E[i]</span></code>s into our prior.</p>
<p>We do this by introducing a <code class="xref py py-class docutils literal"><span class="pre">gvar.GVar</span></code> object <code class="docutils literal"><span class="pre">de[i]</span></code> for each
separate difference <code class="docutils literal"><span class="pre">E[i]-E[i-1]</span></code>, with <code class="docutils literal"><span class="pre">de[0]</span></code> being <code class="docutils literal"><span class="pre">E[0]</span></code>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">de</span> <span class="o">=</span> <span class="p">[</span><span class="n">gvar</span><span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nexp</span><span class="p">)]</span>
<span class="n">de</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">gvar</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>    <span class="c"># different distribution for E[0]</span>
</pre></div>
</div>
<p>Then <code class="docutils literal"><span class="pre">de[0]</span></code> specifies the probability distribution for <code class="docutils literal"><span class="pre">E[0]</span></code>,
<code class="docutils literal"><span class="pre">de[0]+de[1]</span></code> the distribution for <code class="docutils literal"><span class="pre">E[1]</span></code>, <code class="docutils literal"><span class="pre">de[0]+de[1]+de[2]</span></code> the
distribution for <code class="docutils literal"><span class="pre">E[2]</span></code>, and so on. This can be implemented (slightly
inefficiently) in a single line of Python:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">E</span> <span class="o">=</span> <span class="p">[</span><span class="nb">sum</span><span class="p">(</span><span class="n">de</span><span class="p">[:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nexp</span><span class="p">)]</span>
</pre></div>
</div>
<p>For <code class="docutils literal"><span class="pre">nexp=3</span></code>, this implies that</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">E</span><span class="p">)</span>
<span class="go">[1.00(50) 1.90(50) 2.80(50)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">E</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">E</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">E</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">-</span> <span class="n">E</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="go">0.900(10) 0.900(10)</span>
</pre></div>
</div>
<p>which shows that each <code class="docutils literal"><span class="pre">E[i]</span></code> separately has an uncertainty of ±0.5
(approximately) but that differences are specified to within ±0.01.</p>
<p>In the code, we need only change the definition of the prior in order to
introduce these correlations:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">make_prior</span><span class="p">(</span><span class="n">nexp</span><span class="p">):</span>               <span class="c"># make priors for fit parameters</span>
    <span class="n">prior</span> <span class="o">=</span> <span class="n">gv</span><span class="o">.</span><span class="n">BufferDict</span><span class="p">()</span>         <span class="c"># prior -- any dictionary works</span>
    <span class="n">prior</span><span class="p">[</span><span class="s">&#39;a&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">gv</span><span class="o">.</span><span class="n">gvar</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nexp</span><span class="p">)]</span>
    <span class="n">de</span> <span class="o">=</span> <span class="p">[</span><span class="n">gv</span><span class="o">.</span><span class="n">gvar</span><span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nexp</span><span class="p">)]</span>
    <span class="n">de</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">gv</span><span class="o">.</span><span class="n">gvar</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
    <span class="n">prior</span><span class="p">[</span><span class="s">&#39;E&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="nb">sum</span><span class="p">(</span><span class="n">de</span><span class="p">[:</span>    <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nexp</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">prior</span>
</pre></div>
</div>
<p>Running the code as before, but now with the correlated prior in place, we
obtain the following fit with <code class="docutils literal"><span class="pre">nexp=7</span></code> terms:</p>
<div class="highlight-python"><div class="highlight"><pre>************************************* nexp = 7
Least Square Fit:
  chi2/dof [dof] = 0.44 [15]    Q = 0.97    logGBF = 227.47

Parameters:
            a 0    0.4018 (40)      [  0.50 (50) ]  
              1    0.4016 (42)      [  0.50 (50) ]  
              2     0.404 (12)      [  0.50 (50) ]  
              3     0.394 (46)      [  0.50 (50) ]  
              4      0.40 (16)      [  0.50 (50) ]  
              5      0.51 (31)      [  0.50 (50) ]  
              6      0.52 (42)      [  0.50 (50) ]  
            E 0   0.90032 (51)      [  1.00 (50) ]  
              1    1.8001 (11)      [  1.90 (50) ]  
              2     2.701 (10)      [  2.80 (50) ]  
              3     3.601 (14)      [  3.70 (50) ]  
              4     4.501 (17)      [  4.60 (50) ]  
              5     5.401 (20)      [  5.50 (50) ]  
              6     6.301 (22)      [  6.40 (50) ]  

Settings:
  svdcut/n = 1e-15/2    reltol/abstol = 0.0001/0    (itns/time = 3/0.0)

E1/E0 = 1.9994(11)   E2/E0 = 3.000(11)
a1/a0 = 0.9996(25)   a2/a0 = 1.005(28)
</pre></div>
</div>
<p>The results are similar to before for the leading parameters, but
substantially more accurate for parameters describing the second and later
exponential terms, as might be expected given our enhanced knowledge about
the differences between <code class="docutils literal"><span class="pre">E[i]</span></code>s. The output energy differences are
particularly accurate: they range from <code class="docutils literal"><span class="pre">E[1]-E[0]</span> <span class="pre">=</span> <span class="pre">0.900(1)</span></code>, which is
ten times more precise than the prior, to <code class="docutils literal"><span class="pre">E[6]-E[5]</span> <span class="pre">=</span> <span class="pre">0.900(10)</span></code>, which
is just what was put into the fit through the prior (the fit data adds no
new information). The correlated prior allows us to merge our <em>a priori</em>
information about the energy differences with the new information carried
by the fit data <code class="docutils literal"><span class="pre">x,</span> <span class="pre">y</span></code>.</p>
<p>Note that the Gaussian Bayes Factor (see <code class="docutils literal"><span class="pre">logGBF</span></code> in the output) is
significantly larger with the correlated prior (<code class="docutils literal"><span class="pre">logGBF</span> <span class="pre">=</span> <span class="pre">227</span></code>) than it
was for the uncorrelated prior (<code class="docutils literal"><span class="pre">logGBF</span> <span class="pre">=</span> <span class="pre">221</span></code>). Had we been
uncertain as to which prior was more appropriate, this difference says that
the data prefers the correlated prior. (More precisely, it says that we
would be <code class="docutils literal"><span class="pre">exp(227-221)</span> <span class="pre">=</span> <span class="pre">400</span></code> times more likely to get our <code class="docutils literal"><span class="pre">x,y</span></code> data
from a theory with the
correlated prior than from one with the uncorrelated prior.) This
difference is significant despite the fact that the <code class="docutils literal"><span class="pre">chi**2</span></code>s in the two
cases are almost the same. <code class="docutils literal"><span class="pre">chi**2</span></code> tests goodness of fit, but there are
usually more ways than one to get a good fit. Some are more plausible
than others, and the Bayes factor helps sort out which.</p>
</div>
<div class="section" id="tuning-priors-and-the-empirical-bayes-criterion">
<h2>Tuning Priors and the Empirical Bayes Criterion<a class="headerlink" href="#tuning-priors-and-the-empirical-bayes-criterion" title="Permalink to this headline">¶</a></h2>
<p>Given two choices of prior for a parameter, the one that results in a larger
Gaussian Bayes Factor after fitting (see <code class="docutils literal"><span class="pre">logGBF</span></code> in fit output or
<code class="docutils literal"><span class="pre">fit.logGBF</span></code>) is the one preferred by the data. We can use this fact to tune
a prior or set of priors in situations where we are uncertain about the
correct <em>a priori</em> value: we vary the widths and/or central values of the
priors of interest to maximize <code class="docutils literal"><span class="pre">logGBF</span></code>. This leads to complete nonsense if
it is applied to all the priors, but it is useful for tuning (or testing)
limited subsets of the priors when other information is unavailable. In effect
we are using the data to get a feel for what is a reasonable prior. This
procedure for setting priors is called the <em>Empirical Bayes</em> method.</p>
<p>This method is implemented in a driver program</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">fit</span><span class="p">,</span> <span class="n">z</span> <span class="o">=</span> <span class="n">lsqfit</span><span class="o">.</span><span class="n">empbayes_fit</span><span class="p">(</span><span class="n">z0</span><span class="p">,</span> <span class="n">fitargs</span><span class="p">)</span>
</pre></div>
</div>
<p>which varies <code class="xref py py-mod docutils literal"><span class="pre">numpy</span></code> array <code class="docutils literal"><span class="pre">z</span></code>, starting at <code class="docutils literal"><span class="pre">z0</span></code>, to maximize
<code class="docutils literal"><span class="pre">fit.logGBF</span></code> where</p>
<div class="highlight-python"><div class="highlight"><pre>fit = lsqfit.nonlinear_fit(**fitargs(z)).
</pre></div>
</div>
<p>Function <code class="docutils literal"><span class="pre">fitargs(z)</span></code> returns a dictionary containing the arguments for
<code class="xref py py-func docutils literal"><span class="pre">nonlinear_fit()</span></code>. These arguments, and the prior in particular, are
varied as some function of <code class="docutils literal"><span class="pre">z</span></code>. The optimal fit (that is, the one for which
<code class="docutils literal"><span class="pre">fit.logGBF</span></code> is maximum) and <code class="docutils literal"><span class="pre">z</span></code> are returned.</p>
<p>To illustrate, consider tuning the widths of the priors for the amplitudes,
<code class="docutils literal"><span class="pre">prior['a']</span></code>, in the example from the previous section. This is done by
adding the following code to the end of <code class="docutils literal"><span class="pre">main()</span></code> subroutine:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">fitargs</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">nexp</span><span class="o">=</span><span class="n">nexp</span><span class="p">,</span> <span class="n">prior</span><span class="o">=</span><span class="n">prior</span><span class="p">,</span> <span class="n">f</span><span class="o">=</span><span class="n">f</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">p0</span><span class="o">=</span><span class="n">p0</span><span class="p">):</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
    <span class="n">prior</span><span class="p">[</span><span class="s">&#39;a&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">gv</span><span class="o">.</span><span class="n">gvar</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span>   <span class="o">*</span>   <span class="n">z</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nexp</span><span class="p">)]</span>
    <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">prior</span><span class="o">=</span><span class="n">prior</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">fcn</span><span class="o">=</span><span class="n">f</span><span class="p">,</span> <span class="n">p0</span><span class="o">=</span><span class="n">p0</span><span class="p">)</span>
<span class="c">##</span>
<span class="n">z0</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">]</span>
<span class="n">fit</span><span class="p">,</span> <span class="n">z</span> <span class="o">=</span> <span class="n">empbayes_fit</span><span class="p">(</span><span class="n">z0</span><span class="p">,</span> <span class="n">fitargs</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>                  <span class="c"># print the optimized fit results</span>
<span class="n">E</span> <span class="o">=</span> <span class="n">fit</span><span class="o">.</span><span class="n">p</span><span class="p">[</span><span class="s">&#39;E&#39;</span><span class="p">]</span>              <span class="c"># best-fit parameters</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">fit</span><span class="o">.</span><span class="n">p</span><span class="p">[</span><span class="s">&#39;a&#39;</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="s">&#39;E1/E0 =&#39;</span><span class="p">,</span> <span class="n">E</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>  <span class="o">/</span>  <span class="n">E</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s">&#39;  E2/E0 =&#39;</span><span class="p">,</span> <span class="n">E</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>  <span class="o">/</span>  <span class="n">E</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">&#39;a1/a0 =&#39;</span><span class="p">,</span> <span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>  <span class="o">/</span>  <span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s">&#39;  a2/a0 =&#39;</span><span class="p">,</span> <span class="n">a</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>  <span class="o">/</span>  <span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">&quot;prior[&#39;a&#39;] =&quot;</span><span class="p">,</span> <span class="n">fit</span><span class="o">.</span><span class="n">prior</span><span class="p">[</span><span class="s">&#39;a&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
<span class="k">print</span><span class="p">()</span>
</pre></div>
</div>
<p>Function <code class="docutils literal"><span class="pre">fitargs</span></code> generates a dictionary containing the arguments for
<a class="reference internal" href="lsqfit.html#lsqfit.nonlinear_fit" title="lsqfit.nonlinear_fit"><code class="xref py py-class docutils literal"><span class="pre">lsqfit.nonlinear_fit</span></code></a>. These are identical to what we have been using
except that the width of the priors in <code class="docutils literal"><span class="pre">prior['a']</span></code> is adjusted according
to parameter <code class="docutils literal"><span class="pre">z</span></code>. Function <a class="reference internal" href="lsqfit.html#lsqfit.empbayes_fit" title="lsqfit.empbayes_fit"><code class="xref py py-func docutils literal"><span class="pre">lsqfit.empbayes_fit()</span></code></a> does fits for
different values of <code class="docutils literal"><span class="pre">z</span></code> and selects the <code class="docutils literal"><span class="pre">z</span></code> that maximizes <code class="docutils literal"><span class="pre">fit.logGBF</span></code>.
It returns the corresponding fit and the value of <code class="docutils literal"><span class="pre">z</span></code>.</p>
<p>This code generates the following output when <code class="docutils literal"><span class="pre">nexp=7</span></code>:</p>
<div class="highlight-python"><div class="highlight"><pre>Least Square Fit:
  chi2/dof [dof] = 0.77 [15]    Q = 0.71    logGBF = 233.98

Parameters:
            a 0    0.4026 (40)      [ 0.500 (95) ]  *
              1    0.4025 (41)      [ 0.500 (95) ]  *
              2    0.4071 (80)      [ 0.500 (95) ]  
              3     0.385 (20)      [ 0.500 (95) ]  *
              4     0.431 (58)      [ 0.500 (95) ]  
              5     0.477 (74)      [ 0.500 (95) ]  
              6     0.493 (89)      [ 0.500 (95) ]  
            E 0   0.90031 (50)      [  1.00 (50) ]  
              1    1.8000 (10)      [  1.90 (50) ]  
              2    2.7023 (86)      [  2.80 (50) ]  
              3     3.603 (14)      [  3.70 (50) ]  
              4     4.503 (17)      [  4.60 (50) ]  
              5     5.403 (19)      [  5.50 (50) ]  
              6     6.303 (22)      [  6.40 (50) ]  

Settings:
  svdcut/n = 1e-15/2    reltol/abstol = 0.0001/0    (itns/time = 1/0.0)

E1/E0 = 1.9993(10)   E2/E0 = 3.0015(94)
a1/a0 = 0.9995(25)   a2/a0 = 1.011(17)
prior[&#39;a&#39;] = 0.500(95)
</pre></div>
</div>
<p>Reducing the width of the <code class="docutils literal"><span class="pre">prior['a']</span></code>s from 0.5 to 0.1 increased
<code class="docutils literal"><span class="pre">logGBF</span></code> from 227 to 234. The error for <code class="docutils literal"><span class="pre">a2/a0</span></code> is 40%
smaller, but the other results are not much affected &#8212; suggesting that the
details of <code class="docutils literal"><span class="pre">prior['a']</span></code> are not all that important, which is confirmed by
the error budgets generated in the next section. It is not surprising, of
course, that the optimal width is 0.1 since the mean values for the
<code class="docutils literal"><span class="pre">fit.p['a']</span></code>s are clustered around 0.4, which is 0.1 below the mean
value of the priors <code class="docutils literal"><span class="pre">prior['a']</span></code>.</p>
<p>The Bayes factor, <code class="docutils literal"><span class="pre">exp(fit.logGBF)</span></code>, is useful for deciding about fit
functions as well as priors. Consider the following two fits of the sort
discussed in the previous section, one using just two terms in the fit
function and one using three terms:</p>
<div class="highlight-python"><div class="highlight"><pre>************************************* nexp = 2
Least Square Fit:
  chi2/dof [dof] = 0.47 [15]    Q = 0.96    logGBF = 254.15

Parameters:
            a 0    0.4018 (40)      [  0.50 (50) ]  
              1    0.4018 (40)      [  0.50 (50) ]  
            E 0   0.90036 (50)      [  1.00 (50) ]  
              1   1.80036 (50)      [  1.90 (50) ]  

Settings:
  svdcut/n = 1e-15/2    reltol/abstol = 0.0001/0    (itns/time = 6/0.0)


************************************* nexp = 3
Least Square Fit:
  chi2/dof [dof] = 0.5 [15]    Q = 0.94    logGBF = 243.12

Parameters:
            a 0    0.4018 (40)      [  0.50 (50) ]  
              1    0.4018 (40)      [  0.50 (50) ]  
              2      8(10)e-06      [  0.50 (50) ]  
            E 0   0.90035 (50)      [  1.00 (50) ]  
              1   1.80034 (50)      [  1.90 (50) ]  
              2     2.700 (10)      [  2.80 (50) ]  

Settings:
  svdcut/n = 1e-15/2    reltol/abstol = 0.0001/0    (itns/time = 4/0.0)
</pre></div>
</div>
<p>Measured by their <code class="docutils literal"><span class="pre">chi**2</span></code>s, the two fits are almost equally good. The
Bayes factor for the first fit, however, is much larger than that for the
second fit. It says that the probability that our fit data comes from an
underlying theory with exactly two
terms is <code class="docutils literal"><span class="pre">exp(254</span> <span class="pre">-</span> <span class="pre">243)</span> <span class="pre">=</span> <span class="pre">59,874</span></code> times larger than the probability
that it comes from a theory with three terms. In fact, the data comes from
a theory with only two terms since it was generated using the same code
as in the previous section but with <code class="docutils literal"><span class="pre">x,</span> <span class="pre">y</span> <span class="pre">=</span> <span class="pre">make_data(2)</span></code> instead of
<code class="docutils literal"><span class="pre">x,</span> <span class="pre">y</span> <span class="pre">=</span> <span class="pre">make_data()</span></code> in the main program.</p>
</div>
<div class="section" id="partial-errors-and-error-budgets">
<h2>Partial Errors and Error Budgets<a class="headerlink" href="#partial-errors-and-error-budgets" title="Permalink to this headline">¶</a></h2>
<p>We frequently want to know how much of the uncertainty in a fit result is
due to a particular input uncertainty or subset of input uncertainties
(from the input data and/or from the priors). We refer to such errors as
&#8220;partial errors&#8221; (or partial standard deviations) since each is only part
of the total uncertainty in the fit result. The collection of such partial
errors, each associated with a different input error, is called an &#8220;error
budget&#8221; for the fit result. The partial errors from all sources of input
error reproduce the total fit error when they are added in quadrature.</p>
<p>Given the <code class="docutils literal"><span class="pre">fit</span></code> object (an <a class="reference internal" href="lsqfit.html#lsqfit.nonlinear_fit" title="lsqfit.nonlinear_fit"><code class="xref py py-class docutils literal"><span class="pre">lsqfit.nonlinear_fit</span></code></a> object) from the
example in the section on <a class="reference internal" href="#correlated-parameters"><span>Correlated Parameters; Gaussian Bayes Factor</span></a>, for example, we can
extract such information using <code class="xref py py-meth docutils literal"><span class="pre">gvar.GVar.partialsdev()</span></code> &#8212; for example:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">E</span> <span class="o">=</span> <span class="n">fit</span><span class="o">.</span><span class="n">p</span><span class="p">[</span><span class="s">&#39;E&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">fit</span><span class="o">.</span><span class="n">p</span><span class="p">[</span><span class="s">&#39;a&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">E</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">E</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="go">1.9994(11)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">((</span><span class="n">E</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">E</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">partialsdev</span><span class="p">(</span><span class="n">fit</span><span class="o">.</span><span class="n">prior</span><span class="p">[</span><span class="s">&#39;E&#39;</span><span class="p">]))</span>
<span class="go">0.000419224372045</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">((</span><span class="n">E</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">E</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">partialsdev</span><span class="p">(</span><span class="n">fit</span><span class="o">.</span><span class="n">prior</span><span class="p">[</span><span class="s">&#39;a&#39;</span><span class="p">]))</span>
<span class="go">0.000158887614136</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">((</span><span class="n">E</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">E</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">partialsdev</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
<span class="go">0.000953230539699</span>
</pre></div>
</div>
<p>This shows that the total uncertainty in <code class="docutils literal"><span class="pre">E[1]/E[0]</span></code>, 0.00106, is
the sum in quadrature of a contribution 0.00042 due to the priors
specified by <code class="docutils literal"><span class="pre">prior['E']</span></code>, 0.00016 due to <code class="docutils literal"><span class="pre">prior['a']</span></code>, and
0.00095 from the statistical errors in the input data <code class="docutils literal"><span class="pre">y</span></code>.</p>
<p>There are two utility functions for tabulating results and error budgets.
They require dictionaries of output results and inputs, and use the
keys from the dictionaries to label columns and rows, respectively, in
an error-budget table:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">outputs</span> <span class="o">=</span> <span class="p">{</span>
          <span class="s">&#39;E1/E0&#39;</span><span class="p">:</span><span class="n">E</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">E</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s">&#39;E2/E0&#39;</span><span class="p">:</span><span class="n">E</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">/</span> <span class="n">E</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
          <span class="s">&#39;a1/a0&#39;</span><span class="p">:</span><span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s">&#39;a2/a0&#39;</span><span class="p">:</span><span class="n">a</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">/</span> <span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
          <span class="p">}</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;E&#39;</span><span class="p">:</span><span class="n">fit</span><span class="o">.</span><span class="n">prior</span><span class="p">[</span><span class="s">&#39;E&#39;</span><span class="p">],</span> <span class="s">&#39;a&#39;</span><span class="p">:</span><span class="n">fit</span><span class="o">.</span><span class="n">prior</span><span class="p">[</span><span class="s">&#39;a&#39;</span><span class="p">],</span> <span class="s">&#39;y&#39;</span><span class="p">:</span><span class="n">y</span><span class="p">}</span>
<span class="k">print</span><span class="p">(</span><span class="n">fit</span><span class="o">.</span><span class="n">fmt_values</span><span class="p">(</span><span class="n">outputs</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">fit</span><span class="o">.</span><span class="n">fmt_errorbudget</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">inputs</span><span class="p">))</span>
</pre></div>
</div>
<p>This gives the following output:</p>
<div class="highlight-python"><div class="highlight"><pre>Values:
              E2/E0: 3.000(11)           
              E1/E0: 1.9994(11)          
              a2/a0: 1.005(28)           
              a1/a0: 0.9996(25)          

Partial % Errors:
               E2/E0     E1/E0     a2/a0     a1/a0
--------------------------------------------------
        a:      0.09      0.01      1.09      0.02
        y:      0.07      0.05      0.77      0.19
        E:      0.35      0.02      2.44      0.16
--------------------------------------------------
    total:      0.37      0.05      2.79      0.25
</pre></div>
</div>
<p>This table shows, for example, that the 0.37% uncertainty in <code class="docutils literal"><span class="pre">E2/E0</span></code>
comes from a 0.09% contribution due to <code class="docutils literal"><span class="pre">prior['a']</span></code>, a 0.07% contribution
due to due to statistical errors in the fit data <code class="docutils literal"><span class="pre">y</span></code>, and a 0.35%
contribution due to <code class="docutils literal"><span class="pre">prior['E']</span></code>, where, again, the total error is the
sum in quadrature of the partial errors. This suggests that reducing the
statistical errors in the input <code class="docutils literal"><span class="pre">y</span></code> data would reduce the error in
<code class="docutils literal"><span class="pre">E2/E0</span></code> only slightly. On the other hand, more accurate <code class="docutils literal"><span class="pre">y</span></code> data should
significantly reduce the errors in <code class="docutils literal"><span class="pre">E1/E0</span></code> and <code class="docutils literal"><span class="pre">a1/a0</span></code>, where <code class="docutils literal"><span class="pre">y</span></code> is
the dominant source of uncertainty. In fact a four-fold reduction in the
<code class="docutils literal"><span class="pre">y</span></code> errors reduces the <code class="docutils literal"><span class="pre">E1/E0</span></code> error to 0.02% (from 0.05%) while
leaving the <code class="docutils literal"><span class="pre">E2/E0</span></code> error at 0.37%.</p>
</div>
<div class="section" id="y-has-no-error-bars">
<h2><code class="docutils literal"><span class="pre">y</span></code> has No Error Bars<a class="headerlink" href="#y-has-no-error-bars" title="Permalink to this headline">¶</a></h2>
<p>Occasionally there are fit problems where values for the dependent
variable <code class="docutils literal"><span class="pre">y</span></code> are known exactly (to machine precision). This poses a
problem for least-squares fitting since the <code class="docutils literal"><span class="pre">chi**2</span></code> function is
infinite when standard deviations are zero. How does one assign errors
to exact <code class="docutils literal"><span class="pre">y</span></code>s in order to define a <code class="docutils literal"><span class="pre">chi**2</span></code> function that can be
usefully minimized?</p>
<p>It is almost always the case in physical applications of this sort that the
fit function has in principle an infinite number of parameters. It is, of
course, impossible to extract information about infinitely many parameters
from a finite number of <code class="docutils literal"><span class="pre">y</span></code>s. In practice, however, we generally care about
only a few of the parameters in the fit function. (If this isn&#8217;t the case,
give up.) The goal for a least-squares fit is to figure out what a finite
number of exact <code class="docutils literal"><span class="pre">y</span></code>s can tell us about the parameters we want to know.</p>
<p>The key idea here is to use priors to model the part of the fit function
that we don&#8217;t care about, and to remove that part of the function from
the analysis by subtracting or dividing it out from the input data. To
illustrate, consider again the example described in the section on
<a class="reference internal" href="#correlated-parameters"><span>Correlated Parameters; Gaussian Bayes Factor</span></a>. Let us imagine that we know the exact values
for <code class="docutils literal"><span class="pre">y</span></code> for each of <code class="docutils literal"><span class="pre">x=1,</span> <span class="pre">1.2,</span> <span class="pre">1.4...2.6,</span> <span class="pre">2.8</span></code>. We are fitting this
data with a sum of exponentials <code class="docutils literal"><span class="pre">a[i]*exp(-E[i]*x)</span></code> where now we will
assume that <em>a priori</em> we know that: <code class="docutils literal"><span class="pre">E[0]=1.0(5)</span></code>,
<code class="docutils literal"><span class="pre">E[i+1]-E[i]=0.9(2)</span></code>, and <code class="docutils literal"><span class="pre">a[i]=0.5(5)</span></code>. Suppose that our goal is to
find good estimates for <code class="docutils literal"><span class="pre">E[0]</span></code> and <code class="docutils literal"><span class="pre">a[0]</span></code>.</p>
<p>We know that for some set of parameters</p>
<div class="highlight-python"><div class="highlight"><pre>y = sum_i=0..inf  a[i]*exp(-E[i]*x)
</pre></div>
</div>
<p>for each <code class="docutils literal"><span class="pre">x</span></code>-<code class="docutils literal"><span class="pre">y</span></code> pair in our fit data. Given that
<code class="docutils literal"><span class="pre">a[0]</span></code> and <code class="docutils literal"><span class="pre">E[0]</span></code> are all we want to know, we might imagine defining
a new, modified dependent variable <code class="docutils literal"><span class="pre">ymod</span></code>, equal to just
<code class="docutils literal"><span class="pre">a[0]*exp(-E[0]*x)</span></code>:</p>
<div class="highlight-python"><div class="highlight"><pre>ymod = y - sum_i=1..inf a[i]*exp(-E[i]*x)
</pre></div>
</div>
<p>We know everything on the right-hand side of this equation: we have exact
values for <code class="docutils literal"><span class="pre">y</span></code> and we have <em>a priori</em> estimates for the <code class="docutils literal"><span class="pre">a[i]</span></code> and
<code class="docutils literal"><span class="pre">E[i]</span></code> with <code class="docutils literal"><span class="pre">i&gt;0</span></code>. So given means and standard deviations for every
<code class="docutils literal"><span class="pre">i&gt;0</span></code> parameter, and the exact <code class="docutils literal"><span class="pre">y</span></code>, we can determine a
mean and standard deviation for <code class="docutils literal"><span class="pre">ymod</span></code>. The strategy then is to compute
the corresponding <code class="docutils literal"><span class="pre">ymod</span></code> for every <code class="docutils literal"><span class="pre">y</span></code> and <code class="docutils literal"><span class="pre">x</span></code> pair, and then fit
<code class="docutils literal"><span class="pre">ymod</span></code> versus <code class="docutils literal"><span class="pre">x</span></code> to the <em>single</em> exponential <code class="docutils literal"><span class="pre">a[0]*exp(-E[0]*t)</span></code>.
That fit will give values for <code class="docutils literal"><span class="pre">a[0]</span></code> and <code class="docutils literal"><span class="pre">E[0]</span></code> that reflect the
uncertainties in <code class="docutils literal"><span class="pre">ymod</span></code>, which in turn originate in uncertainties in our
knowledge about the parameters for the <code class="docutils literal"><span class="pre">i&gt;0</span></code> exponentials.</p>
<p>It turns out to be quite simple to implement such a strategy using
<code class="xref py py-class docutils literal"><span class="pre">gvar.GVar</span></code>s. We convert our code by first modifying the main
program so that it provides prior information to a subroutine that computes
<code class="docutils literal"><span class="pre">ymod</span></code>. We will vary the number of terms <code class="docutils literal"><span class="pre">nexp</span></code> that are kept in the
fit, putting the rest into <code class="docutils literal"><span class="pre">ymod</span></code> as above (up to a maximum of 20
terms, which is close enough to infinity):</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">gv</span><span class="o">.</span><span class="n">ranseed</span><span class="p">([</span><span class="mi">2009</span><span class="p">,</span> <span class="mi">2010</span><span class="p">,</span> <span class="mi">2011</span><span class="p">,</span> <span class="mi">2012</span><span class="p">])</span>  <span class="c"># initialize random numbers (opt.)</span>
    <span class="n">max_prior</span> <span class="o">=</span> <span class="n">make_prior</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>         <span class="c"># maximum sized prior</span>
    <span class="n">p0</span> <span class="o">=</span> <span class="bp">None</span>                          <span class="c"># make larger fits go faster (opt.)</span>
    <span class="k">for</span> <span class="n">nexp</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="s">&#39;************************************* nexp =&#39;</span><span class="p">,</span> <span class="n">nexp</span><span class="p">)</span>
        <span class="n">fit_prior</span> <span class="o">=</span> <span class="n">gv</span><span class="o">.</span><span class="n">BufferDict</span><span class="p">()</span>    <span class="c"># part of max_pior used in fit</span>
        <span class="n">ymod_prior</span> <span class="o">=</span> <span class="n">gv</span><span class="o">.</span><span class="n">BufferDict</span><span class="p">()</span>   <span class="c"># part of max_prior absorbed in ymod</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">max_prior</span><span class="p">:</span>
            <span class="n">fit_prior</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">max_prior</span><span class="p">[</span><span class="n">k</span><span class="p">][:</span><span class="n">nexp</span><span class="p">]</span>
            <span class="n">ymod_prior</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">max_prior</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">nexp</span><span class="p">:]</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_data</span><span class="p">(</span><span class="n">ymod_prior</span><span class="p">)</span>   <span class="c"># make fit data</span>
        <span class="n">fit</span> <span class="o">=</span> <span class="n">lsqfit</span><span class="o">.</span><span class="n">nonlinear_fit</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">fcn</span><span class="o">=</span><span class="n">f</span><span class="p">,</span> <span class="n">prior</span><span class="o">=</span><span class="n">fit_prior</span><span class="p">,</span> <span class="n">p0</span><span class="o">=</span><span class="n">p0</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="n">fit</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">maxline</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>          <span class="c"># print the fit results</span>
        <span class="k">print</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">fit</span><span class="o">.</span><span class="n">chi2</span><span class="o">/</span><span class="n">fit</span><span class="o">.</span><span class="n">dof</span><span class="o">&lt;</span><span class="mf">1.</span><span class="p">:</span>
            <span class="n">p0</span> <span class="o">=</span> <span class="n">fit</span><span class="o">.</span><span class="n">pmean</span>             <span class="c"># starting point for next fit (opt.)</span>
</pre></div>
</div>
<p>We put all of our <em>a priori</em> knowledge about parameters into prior
<code class="docutils literal"><span class="pre">max_prior</span></code> and then pull out the part we need for the fit &#8212; that is,
the first <code class="docutils literal"><span class="pre">nexp</span></code> terms. The remaining part of <code class="docutils literal"><span class="pre">max_prior</span></code> is used to
correct the exact data, which comes from a new <code class="docutils literal"><span class="pre">make_data</span></code>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">make_data</span><span class="p">(</span><span class="n">ymod_prior</span><span class="p">):</span>          <span class="c"># make x, y fit data</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="mi">10</span> <span class="o">*</span> <span class="mf">0.2</span> <span class="o">+</span>  <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">)</span>
    <span class="n">ymod</span> <span class="o">=</span> <span class="n">f_exact</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">ymod_prior</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">ymod</span>
</pre></div>
</div>
<p>Running the new code produces the following output, where again <code class="docutils literal"><span class="pre">nexp</span></code> is
the number of exponentials kept in the fit (and <code class="docutils literal"><span class="pre">20-nexp</span></code> is the number
pushed into the modified dependent variable <code class="docutils literal"><span class="pre">ymod</span></code>):</p>
<div class="highlight-python"><div class="highlight"><pre>************************************* nexp = 1
Least Square Fit:
  chi2/dof [dof] = 0.051 [10]    Q = 1    logGBF = 97.499

Parameters:
            a 0    0.4009 (14)      [  0.50 (50) ]  
            E 0   0.90033 (62)      [  1.00 (50) ]  

Fit:
     x[k]           y[k]        f(x[k],p)
-----------------------------------------
        1      0.15 (11)     0.16292 (47)  
      1.2     0.128 (74)     0.13607 (38)  
      1.4     0.110 (52)     0.11365 (30)  
      1.6     0.093 (37)     0.09492 (24)  
      1.8     0.078 (26)     0.07928 (19)  
        2     0.066 (18)     0.06622 (15)  
      2.2     0.055 (13)     0.05531 (12)  
      2.4    0.0462 (93)    0.046192 (94)  
      2.6    0.0387 (66)    0.038581 (74)  
      2.8    0.0323 (47)    0.032223 (58)  

Settings:
  svdcut/n = 1e-15/2    reltol/abstol = 0.0001/0    (itns/time = 5/0.0)


************************************* nexp = 2
Least Square Fit:
  chi2/dof [dof] = 0.053 [10]    Q = 1    logGBF = 99.041

Parameters:
            a 0    0.4002 (13)      [  0.50 (50) ]  
              1     0.405 (36)      [  0.50 (50) ]  
            E 0   0.90006 (55)      [  1.00 (50) ]  
              1     1.803 (30)      [  1.90 (54) ]  

Fit:
     x[k]            y[k]        f(x[k],p)
------------------------------------------
        1      0.223 (45)      0.2293 (44)  
      1.2      0.179 (26)      0.1823 (28)  
      1.4      0.145 (15)      0.1459 (18)  
      1.6     0.1168 (90)      0.1174 (12)  
      1.8     0.0947 (53)     0.09492 (74)  
        2     0.0770 (32)     0.07711 (47)  
      2.2     0.0628 (19)     0.06289 (30)  
      2.4     0.0515 (11)     0.05148 (19)  
      2.6    0.04226 (67)     0.04226 (12)  
      2.8    0.03479 (40)    0.034784 (72)  

Settings:
  svdcut/n = 1e-15/2    reltol/abstol = 0.0001/0    (itns/time = 3/0.0)


************************************* nexp = 3
Least Square Fit:
  chi2/dof [dof] = 0.057 [10]    Q = 1    logGBF = 99.844

Parameters:
            a 0   0.39998 (93)      [  0.50 (50) ]  
              1     0.399 (35)      [  0.50 (50) ]  
              2     0.401 (99)      [  0.50 (50) ]  
            E 0   0.89999 (36)      [  1.00 (50) ]  
              1     1.799 (26)      [  1.90 (54) ]  
              2      2.70 (20)      [  2.80 (57) ]  

Fit:
     x[k]             y[k]        f(x[k],p)
-------------------------------------------
        1       0.253 (19)      0.2557 (54)  
      1.2      0.1968 (91)      0.1977 (28)  
      1.4      0.1545 (45)      0.1548 (14)  
      1.6      0.1224 (22)     0.12256 (75)  
      1.8      0.0979 (11)     0.09793 (39)  
        2     0.07885 (54)     0.07886 (20)  
      2.2     0.06391 (27)     0.06391 (10)  
      2.4     0.05206 (13)    0.052065 (51)  
      2.6    0.042602 (67)    0.042601 (26)  
      2.8    0.034983 (33)    0.034982 (13)  

Settings:
  svdcut/n = 1e-15/2    reltol/abstol = 0.0001/0    (itns/time = 4/0.0)


************************************* nexp = 4
Least Square Fit:
  chi2/dof [dof] = 0.057 [10]    Q = 1    logGBF = 99.842

Parameters:
            a 0   0.39995 (77)      [  0.50 (50) ]  
              1     0.399 (32)      [  0.50 (50) ]  
              2      0.40 (10)      [  0.50 (50) ]  
              3      0.40 (15)      [  0.50 (50) ]  
            E 0   0.89998 (30)      [  1.00 (50) ]  
              1     1.799 (23)      [  1.90 (54) ]  
              2      2.70 (19)      [  2.80 (57) ]  
              3      3.61 (28)      [  3.70 (61) ]  

Fit:
     x[k]              y[k]         f(x[k],p)
---------------------------------------------
        1       0.2656 (78)       0.2666 (23)  
      1.2       0.2027 (32)      0.20297 (98)  
      1.4       0.1573 (13)      0.15737 (43)  
      1.6      0.12378 (54)      0.12381 (18)  
      1.8      0.09853 (22)     0.098540 (79)  
        2     0.079153 (93)     0.079155 (34)  
      2.2     0.064051 (39)     0.064051 (15)  
      2.4     0.052134 (16)    0.0521344 (62)  
      2.6    0.0426348 (67)    0.0426347 (26)  
      2.8    0.0349985 (28)    0.0349985 (11)  

Settings:
  svdcut/n = 1e-15/2    reltol/abstol = 0.0001/0    (itns/time = 4/0.0)


E1/E0 = 1.999(25)   E2/E0 = 3.00(22)
a1/a0 = 0.997(79)   a2/a0 = 1.01(27)
</pre></div>
</div>
<p>Here we use <code class="docutils literal"><span class="pre">fit.format(maxline=True)</span></code> to print out a table of <code class="docutils literal"><span class="pre">x</span></code> and
<code class="docutils literal"><span class="pre">y</span></code> (actually <code class="docutils literal"><span class="pre">ymod</span></code>) values, together with the value of the
fit function using the best-fit parameters. There are several things
to notice:</p>
<blockquote>
<div><ul>
<li><p class="first">Were we really only interested in <code class="docutils literal"><span class="pre">a[0]</span></code> and <code class="docutils literal"><span class="pre">E[0]</span></code>, a
single-exponential fit would have been adequate. This is because we
are in effect doing a 20-exponential fit even in that case, by
including all but the first term as corrections to <code class="docutils literal"><span class="pre">y</span></code>. The answers
given by the first fit are correct (we know the exact values since we
are using fake data).</p>
<p>The ability to push uninteresting parameters into a <code class="docutils literal"><span class="pre">ymod</span></code> can be
highly useful in practice since it is usually much cheaper to
incorporate those fit parameters into <code class="docutils literal"><span class="pre">ymod</span></code> than it is to include
them as fit parameters &#8212; fits with smaller numbers of parameters are
usually a lot faster.</p>
</li>
<li><p class="first">The <code class="docutils literal"><span class="pre">chi**2</span></code> and best-fit parameter means and standard deviations
are almost unchanged by shifting terms from <code class="docutils literal"><span class="pre">ymod</span></code> back into the
fit function, as <code class="docutils literal"><span class="pre">nexp</span></code> increases. The final results for
<code class="docutils literal"><span class="pre">a[0]</span></code> and <code class="docutils literal"><span class="pre">E[0]</span></code>, for example, are nearly identical in the
<code class="docutils literal"><span class="pre">nexp=1</span></code> and <code class="docutils literal"><span class="pre">nexp=4</span></code> fits.</p>
<p>In fact it is straightforward to prove that best-fit parameter means
and standard deviations, as well as <code class="docutils literal"><span class="pre">chi**2</span></code>, should be exactly the
same in such situations provided the fit function is linear in all fit
parameters. Here the fit function is approximately linear, given our
small standard deviations, and so results are only approximately
independent of <code class="docutils literal"><span class="pre">nexp</span></code>.</p>
</li>
<li><p class="first">The uncertainty in <code class="docutils literal"><span class="pre">ymod</span></code> for a particular <code class="docutils literal"><span class="pre">x</span></code> decreases as
<code class="docutils literal"><span class="pre">nexp</span></code> increases and as <code class="docutils literal"><span class="pre">x</span></code> increases. Also the <code class="docutils literal"><span class="pre">nexp</span></code>
independence of the fit results depends upon capturing all of the
correlations in the correction to <code class="docutils literal"><span class="pre">y</span></code>. This is why
<code class="xref py py-class docutils literal"><span class="pre">gvar.GVar</span></code>s are useful since they make the implementation of
those correlations trivial.</p>
</li>
<li><p class="first">Although we motivated this example by the need to deal with <code class="docutils literal"><span class="pre">y</span></code>s
having no errors, it is straightforward to apply the same ideas to
a situation where the <code class="docutils literal"><span class="pre">y</span></code>s have errors. Again one might want to
do so since fitting uninteresting fit parameters is generally more
costly than absorbing them into the <code class="docutils literal"><span class="pre">y</span></code> (which then has a modified
mean and standard deviation).</p>
</li>
</ul>
</div></blockquote>
</div>
<div class="section" id="svd-cuts-and-roundoff-error">
<h2>SVD Cuts and Roundoff Error<a class="headerlink" href="#svd-cuts-and-roundoff-error" title="Permalink to this headline">¶</a></h2>
<p>All of the fits discussed above have (default) SVD cuts of 1e-15. This
has little impact in most of the problems, but makes a big difference
in the problem discussed in the previous section. Had we run that fit,
for example, with an SVD cut of 1e-19, instead of 1e-15, we would have
obtained the following output:</p>
<div class="highlight-python"><div class="highlight"><pre>Least Square Fit:
  chi2/dof [dof] = 0.057 [10]    Q = 1    logGBF = 99.847

Parameters:
            a 0   0.39994 (77)      [  0.50 (50) ]  
              1     0.398 (32)      [  0.50 (50) ]  
              2      0.40 (10)      [  0.50 (50) ]  
              3      0.40 (15)      [  0.50 (50) ]  
            E 0   0.89997 (30)      [  1.00 (50) ]  
              1     1.799 (23)      [  1.90 (54) ]  
              2      2.70 (19)      [  2.80 (57) ]  
              3      3.61 (28)      [  3.70 (61) ]  

Fit:
     x[k]              y[k]        f(x[k],p)
--------------------------------------------
        1       0.2656 (78)      0.2666 (57)  
      1.2       0.2027 (32)      0.2030 (23)  
      1.4       0.1573 (13)     0.15737 (92)  
      1.6      0.12378 (54)     0.12381 (35)  
      1.8      0.09853 (22)     0.09854 (12)  
        2     0.079153 (93)    0.079155 (37)  
      2.2     0.064051 (39)    0.064051 (18)  
      2.4     0.052134 (16)    0.052134 (20)  
      2.6    0.0426348 (67)    0.042635 (19)  
      2.8    0.0349985 (28)    0.034998 (17)  

Settings:
  svdcut/n = 1e-19/0    reltol/abstol = 0.0001/0    (itns/time = 5/0.0)


E1/E0 = 2.00(49)   E2/E0 = 3.0(3.8)
a1/a0 = 1.0(1.5)   a2/a0 = 1.0(3.3)
</pre></div>
</div>
<p>The standard deviations quoted for <code class="docutils literal"><span class="pre">E1/E0</span></code>, <em>etc.</em> are much too large
compared with the standard deviations shown for the individual parameters,
and much larger than what we obtained in the previous section.
This is due to roundoff error. The standard deviations quoted for the
parameters are computed differently from the standard deviations in
<code class="docutils literal"><span class="pre">fit.p</span></code> (which was used to calculate <code class="docutils literal"><span class="pre">E1/E0</span></code>). The former come directly
from the curvature of the <code class="docutils literal"><span class="pre">chi**2</span></code> function at its minimum; the latter
are related back to the standard deviations of the input data and priors
used in the fit. The two should agree, but they will not agree if the
covariance matrix for the input <code class="docutils literal"><span class="pre">y</span></code> data is too ill-conditioned.</p>
<p>The inverse of the <code class="docutils literal"><span class="pre">y</span></code>&#8211;<code class="docutils literal"><span class="pre">prior</span></code> covariance matrix is used in the <code class="docutils literal"><span class="pre">chi**2</span></code>
function that is minimized by <a class="reference internal" href="lsqfit.html#lsqfit.nonlinear_fit" title="lsqfit.nonlinear_fit"><code class="xref py py-class docutils literal"><span class="pre">lsqfit.nonlinear_fit</span></code></a>. Given the
finite precision of computer hardware, it is impossible to compute this
inverse accurately if the matrix is singular or almost singular, and in
such situations the reliability of the fit results is in question. The
eigenvalues of the covariance matrix in this example (for <code class="docutils literal"><span class="pre">nexp=6</span></code>)
indicate that this is the case: they range from <code class="docutils literal"><span class="pre">7.2e-5</span></code> down to
<code class="docutils literal"><span class="pre">4.2e-26</span></code>, covering 21 orders of magnitude. This is likely too large a
range to be handled with the 16&#8211;18 digits of precision available in normal
double precision computation. The smallest eigenvalues and their
eigenvectors are likely to be quite inaccurate, as is any method for
computing the inverse matrix.</p>
<p>One solution to this common problem in least-squares fitting is
to introduce an SVD cut, here called <code class="docutils literal"><span class="pre">svdcut</span></code>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">fit</span> <span class="o">=</span> <span class="n">nonlinear_fit</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">ymod</span><span class="p">),</span> <span class="n">fcn</span><span class="o">=</span><span class="n">f</span><span class="p">,</span> <span class="n">prior</span><span class="o">=</span><span class="n">prior</span><span class="p">,</span> <span class="n">p0</span><span class="o">=</span><span class="n">p0</span><span class="p">,</span> <span class="n">svdcut</span><span class="o">=</span><span class="mf">1e-15</span><span class="p">)</span>
</pre></div>
</div>
<p>This regulates the singularity of the covariance matrix by, in effect,
replacing its smallest eigenvalues with a larger, minimum
eigenvalue. The cost is less precision in the final results
since we are decreasing the
precision of the input <code class="docutils literal"><span class="pre">y</span></code> data. This is a conservative move, but numerical
stability is worth the tradeoff. The listing shows that 2 eigenvalues are
modified when <code class="docutils literal"><span class="pre">svdcut=1e-15</span></code> (see entry for <code class="docutils literal"><span class="pre">svdcut/n</span></code>); no
eigenvalues are changed when <code class="docutils literal"><span class="pre">svdcut=1e-19</span></code>.</p>
<p>The SVD cut is actually applied to the correlation matrix, which is the
covariance matrix rescaled by standard deviations so that  all diagonal
elements equal 1. Working with the correlation matrix rather than the
covariance matrix helps mitigate problems caused by large scale differences
between different variables. Eigenvalues of the correlation matrix that are
smaller than a minimum eigenvalue, equal to <code class="docutils literal"><span class="pre">svdcut</span></code> times the largest
eigenvalue,  are replaced by the minimum eigenvalue, while leaving their
eigenvectors unchanged. This defines a new, less singular correlation matrix
from which a new, less singular covariance matrix is constructed. Larger
values of <code class="docutils literal"><span class="pre">svdcut</span></code> affect larger numbers of eigenmodes and increase errors
in the final results.</p>
<p>The error budget is different in the example above. There is no contribution from
the original <code class="docutils literal"><span class="pre">y</span></code> data since it is exact. So all statistical uncertainty
comes from the priors in <code class="docutils literal"><span class="pre">max_prior</span></code>, and from the SVD cut, which
contributes since it modifies the effective variances of several eigenmodes of
the correlation matrix. The SVD contribution to the error can be obtained from
<code class="docutils literal"><span class="pre">fit.svdcorrection</span></code>, so the full error budget is constructed by the following
code,</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">outputs</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;E1/E0&#39;</span><span class="p">:</span><span class="n">E</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">E</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s">&#39;E2/E0&#39;</span><span class="p">:</span><span class="n">E</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">/</span> <span class="n">E</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
           <span class="s">&#39;a1/a0&#39;</span><span class="p">:</span><span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s">&#39;a2/a0&#39;</span><span class="p">:</span><span class="n">a</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">/</span> <span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">]}</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;E&#39;</span><span class="p">:</span><span class="n">max_prior</span><span class="p">[</span><span class="s">&#39;E&#39;</span><span class="p">],</span> <span class="s">&#39;a&#39;</span><span class="p">:</span><span class="n">max_prior</span><span class="p">[</span><span class="s">&#39;a&#39;</span><span class="p">],</span> <span class="s">&#39;svd&#39;</span><span class="p">:</span><span class="n">fit</span><span class="o">.</span><span class="n">svdcorrection</span><span class="p">}</span>
<span class="k">print</span><span class="p">(</span><span class="n">fit</span><span class="o">.</span><span class="n">fmt_values</span><span class="p">(</span><span class="n">outputs</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">fit</span><span class="o">.</span><span class="n">fmt_errorbudget</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">inputs</span><span class="p">))</span>
</pre></div>
</div>
<p>which gives:</p>
<div class="highlight-python"><div class="highlight"><pre>Values:
              E2/E0: 3.00(22)            
              E1/E0: 1.999(25)           
              a2/a0: 1.01(27)            
              a1/a0: 0.997(79)           

Partial % Errors:
               E2/E0     E1/E0     a2/a0     a1/a0
--------------------------------------------------
        a:      3.32      0.64     10.30      3.93
      svd:      0.29      0.10      0.13      0.55
        E:      6.43      1.08     24.38      6.86
--------------------------------------------------
    total:      7.24      1.26     26.46      7.92
</pre></div>
</div>
<p>Here the contribution from the SVD cut is almost negligible, which might
not be the case in other applications.</p>
<p>The SVD cut is applied separately to each block diagonal sub-matrix of the
correlation matrix. This means, among other things, that errors for
uncorrelated data are unaffected by the SVD cut. Applying an SVD
cut of 1e-4, for example, to the following singular covariance matrix,</p>
<div class="highlight-python"><div class="highlight"><pre>[[  1.0   1.0   0.0  ]
 [  1.0   1.0   0.0  ]
 [  0.0   0.0   1e-20]],
</pre></div>
</div>
<p>gives a new, non-singular matrix</p>
<div class="highlight-python"><div class="highlight"><pre>[[  1.0001   0.9999   0.0  ]
 [  0.9999   1.0001   0.0  ]
 [  0.0      0.0      1e-20]]
</pre></div>
</div>
<p>where only the upper right sub-matrix is different.</p>
<p><a class="reference internal" href="lsqfit.html#lsqfit.nonlinear_fit" title="lsqfit.nonlinear_fit"><code class="xref py py-class docutils literal"><span class="pre">lsqfit.nonlinear_fit</span></code></a> uses a default value for <code class="docutils literal"><span class="pre">svdcut</span></code> of 1e-15.
This default can be overridden, as shown above, but for many
problems it is a good choice. Roundoff errors become more accute, however,
when there are strong correlations between different parts of the fit
data or prior.  Then much larger <code class="docutils literal"><span class="pre">svdcut</span></code>s may be needed.</p>
<p>The SVD cut is applied to both the data and the prior. It is possible to
apply SVD cuts to either of these separately using <code class="xref py py-func docutils literal"><span class="pre">gvar.svd()</span></code> before
the fit: for example,</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">ymod</span> <span class="o">=</span> <span class="n">gv</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">ymod</span><span class="p">,</span> <span class="n">svdcut</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">)</span>
<span class="n">prior</span> <span class="o">=</span> <span class="n">gv</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">svdcut</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">)</span>
<span class="n">fit</span> <span class="o">=</span> <span class="n">nonlinear_fit</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">ymod</span><span class="p">),</span> <span class="n">fcn</span><span class="o">=</span><span class="n">f</span><span class="p">,</span> <span class="n">prior</span><span class="o">=</span><span class="n">prior</span><span class="p">,</span> <span class="n">p0</span><span class="o">=</span><span class="n">p0</span><span class="p">,</span> <span class="n">svdcut</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</pre></div>
</div>
<p>applies different SVD cuts to the prior and data.</p>
<p>Note that taking <code class="docutils literal"><span class="pre">svdcut=-1e-15</span></code>, with a
minus sign, causes the problematic modes to be dropped. This is a more
conventional implementation of SVD cuts, but here it results in much less
precision than using <code class="docutils literal"><span class="pre">svdcut=1e-15</span></code> (giving, for example, 1.993(69)
for <code class="docutils literal"><span class="pre">E1/E0</span></code>, which is almost three times less precise). Dropping modes is
equivalent to setting the corresponding variances to infinity, which is
(obviously) much more conservative and less realistic than setting them equal
to the SVD-cutoff variance.</p>
<p>The method <a class="reference internal" href="lsqfit.html#lsqfit.nonlinear_fit.check_roundoff" title="lsqfit.nonlinear_fit.check_roundoff"><code class="xref py py-func docutils literal"><span class="pre">lsqfit.nonlinear_fit.check_roundoff()</span></code></a> can be used to check
for roundoff errors by adding the line <code class="docutils literal"><span class="pre">fit.check_roundoff()</span></code> after the
fit. It generates a warning if roundoff looks to be a problem. This check
is done automatically if <code class="docutils literal"><span class="pre">debug=True</span></code> is added to the argument list of
<a class="reference internal" href="lsqfit.html#lsqfit.nonlinear_fit" title="lsqfit.nonlinear_fit"><code class="xref py py-class docutils literal"><span class="pre">lsqfit.nonlinear_fit</span></code></a>.</p>
</div>
<div class="section" id="bootstrap-error-analysis">
<h2>Bootstrap Error Analysis<a class="headerlink" href="#bootstrap-error-analysis" title="Permalink to this headline">¶</a></h2>
<p>Our analysis above assumes that every probability distribution relevant to
the fit is approximately Gaussian. For example, we characterize the input
data for <code class="docutils literal"><span class="pre">y</span></code> by a mean and a covariance matrix obtained from averaging
many random samples of <code class="docutils literal"><span class="pre">y</span></code>. For large sample sizes it is almost certainly
true that the average values follow a Gaussian distribution, but in
practical applications the sample size could be too small. The <em>statistical
bootstrap</em> is an analysis tool for dealing with such situations.</p>
<p>The strategy is to: 1) make a large number of &#8220;bootstrap copies&#8221; of the
original input data that differ from each other by random amounts
characteristic of the underlying randomness in the original data; 2) repeat
the entire fit analysis for each bootstrap copy of the data, extracting
fit results from each; and 3) use the variation of the fit results from
bootstrap copy to bootstrap copy to determine an approximate probability
distribution (possibly non-Gaussian) for the each result.</p>
<p>Consider the code from the previous section, where we might reasonably want
another check on the error estimates for our results. That code can be
modified to include a bootstrap analysis by adding the following to the end of
the <code class="docutils literal"><span class="pre">main()</span></code> subroutine:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">Nbs</span> <span class="o">=</span> <span class="mi">40</span>                                     <span class="c"># number of bootstrap copies</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;E1/E0&#39;</span><span class="p">:[],</span> <span class="s">&#39;E2/E0&#39;</span><span class="p">:[],</span> <span class="s">&#39;a1/a0&#39;</span><span class="p">:[],</span> <span class="s">&#39;a2/a0&#39;</span><span class="p">:[]}</span>   <span class="c"># results</span>
<span class="k">for</span> <span class="n">bsfit</span> <span class="ow">in</span> <span class="n">fit</span><span class="o">.</span><span class="n">bootstrap_iter</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">Nbs</span><span class="p">):</span>
    <span class="n">E</span> <span class="o">=</span> <span class="n">bsfit</span><span class="o">.</span><span class="n">pmean</span><span class="p">[</span><span class="s">&#39;E&#39;</span><span class="p">]</span>                     <span class="c"># best-fit parameter values</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">bsfit</span><span class="o">.</span><span class="n">pmean</span><span class="p">[</span><span class="s">&#39;a&#39;</span><span class="p">]</span>                     <span class="c">#   (ignore errors)</span>
    <span class="n">outputs</span><span class="p">[</span><span class="s">&#39;E1/E0&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">E</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">E</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>       <span class="c"># accumulate results</span>
    <span class="n">outputs</span><span class="p">[</span><span class="s">&#39;E2/E0&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">E</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">/</span> <span class="n">E</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">outputs</span><span class="p">[</span><span class="s">&#39;a1/a0&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">outputs</span><span class="p">[</span><span class="s">&#39;a2/a0&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">/</span> <span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">outputs</span><span class="p">[</span><span class="s">&#39;E1&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">E</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">outputs</span><span class="p">[</span><span class="s">&#39;a1&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="c"># extract &quot;means&quot; and &quot;standard deviations&quot; from the bootstrap output;</span>
<span class="c"># print using .fmt() to create compact representation of GVars</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">gv</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">avg_data</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">bstrap</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">&#39;Bootstrap results:&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">&#39;E1/E0 =&#39;</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="s">&#39;E1/E0&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fmt</span><span class="p">(),</span> <span class="s">&#39;  E2/E1 =&#39;</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="s">&#39;E2/E0&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fmt</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="s">&#39;a1/a0 =&#39;</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="s">&#39;a1/a0&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fmt</span><span class="p">(),</span> <span class="s">&#39;  a2/a0 =&#39;</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="s">&#39;a2/a0&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fmt</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="s">&#39;E1 =&#39;</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="s">&#39;E1&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fmt</span><span class="p">(),</span> <span class="s">&#39;  a1 =&#39;</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="s">&#39;a1&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fmt</span><span class="p">())</span>
</pre></div>
</div>
<p>The results are consistent with the results obtained directly from the fit
(when using <code class="docutils literal"><span class="pre">svdcut=1e-15</span></code>):</p>
<div class="highlight-python"><div class="highlight"><pre>Bootstrap results:
E1/E0 = 1.999(17)   E2/E1 = 2.96(16)
a1/a0 = 0.992(56)   a2/a0 = 0.93(23)
E1 = 1.799(16)   a1 = 0.397(23)
</pre></div>
</div>
<p>In particular, the bootstrap analysis confirms our previous error estimates
(to within 10-30%, since <code class="docutils literal"><span class="pre">Nbs=40</span></code>). When <code class="docutils literal"><span class="pre">Nbs</span></code> is small, it is often
safer to use the median instead of the mean as the estimator, which is
what <code class="docutils literal"><span class="pre">gv.dataset.avg_data</span></code> does here since flag <code class="docutils literal"><span class="pre">bstrap</span></code> is set
to <code class="docutils literal"><span class="pre">True</span></code>.</p>
</div>
<div class="section" id="testing-fits-with-simulated-data">
<h2>Testing Fits with Simulated Data<a class="headerlink" href="#testing-fits-with-simulated-data" title="Permalink to this headline">¶</a></h2>
<p>Ideally we would test a fitting protocol by doing fits of data similar to
our actual fit but where we know the correct values for the fit parameters
ahead of the fit. The <a class="reference internal" href="lsqfit.html#lsqfit.nonlinear_fit" title="lsqfit.nonlinear_fit"><code class="xref py py-class docutils literal"><span class="pre">lsqfit.nonlinear_fit</span></code></a> iterator <code class="docutils literal"><span class="pre">simulated_fit_iter</span></code>
creates any number of such simulations of the original fit. Returning
again to the fits in the section on <a class="reference internal" href="#correlated-parameters"><span>Correlated Parameters; Gaussian Bayes Factor</span></a>, we
can add three fit simulations to the end of the <code class="docutils literal"><span class="pre">main</span></code> program:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">gv</span><span class="o">.</span><span class="n">ranseed</span><span class="p">([</span><span class="mi">2009</span><span class="p">,</span> <span class="mi">2010</span><span class="p">,</span> <span class="mi">2011</span><span class="p">,</span> <span class="mi">2012</span><span class="p">])</span> <span class="c"># initialize random numbers (opt.)</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_data</span><span class="p">()</span>              <span class="c"># make fit data</span>
    <span class="n">p0</span> <span class="o">=</span> <span class="bp">None</span>                       <span class="c"># make larger fits go faster (opt.)</span>
    <span class="k">for</span> <span class="n">nexp</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">20</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="s">&#39;************************************* nexp =&#39;</span><span class="p">,</span> <span class="n">nexp</span><span class="p">)</span>
        <span class="n">prior</span> <span class="o">=</span> <span class="n">make_prior</span><span class="p">(</span><span class="n">nexp</span><span class="p">)</span>
        <span class="n">fit</span> <span class="o">=</span> <span class="n">lsqfit</span><span class="o">.</span><span class="n">nonlinear_fit</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">fcn</span><span class="o">=</span><span class="n">f</span><span class="p">,</span> <span class="n">prior</span><span class="o">=</span><span class="n">prior</span><span class="p">,</span> <span class="n">p0</span><span class="o">=</span><span class="n">p0</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>                  <span class="c"># print the fit results</span>
        <span class="n">E</span> <span class="o">=</span> <span class="n">fit</span><span class="o">.</span><span class="n">p</span><span class="p">[</span><span class="s">&#39;E&#39;</span><span class="p">]</span>              <span class="c"># best-fit parameters</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">fit</span><span class="o">.</span><span class="n">p</span><span class="p">[</span><span class="s">&#39;a&#39;</span><span class="p">]</span>
        <span class="k">print</span><span class="p">(</span><span class="s">&#39;E1/E0 =&#39;</span><span class="p">,</span> <span class="n">E</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">E</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s">&#39;  E2/E0 =&#39;</span><span class="p">,</span> <span class="n">E</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">/</span> <span class="n">E</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">print</span><span class="p">(</span><span class="s">&#39;a1/a0 =&#39;</span><span class="p">,</span> <span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s">&#39;  a2/a0 =&#39;</span><span class="p">,</span> <span class="n">a</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">/</span> <span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">print</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">fit</span><span class="o">.</span><span class="n">chi2</span> <span class="o">/</span> <span class="n">fit</span><span class="o">.</span><span class="n">dof</span> <span class="o">&lt;</span> <span class="mf">1.</span><span class="p">:</span>
            <span class="n">p0</span> <span class="o">=</span> <span class="n">fit</span><span class="o">.</span><span class="n">pmean</span>          <span class="c"># starting point for next fit (opt.)</span>

    <span class="c"># 3 fit simulations based upon last fit</span>
    <span class="k">for</span> <span class="n">sfit</span> <span class="ow">in</span> <span class="n">fit</span><span class="o">.</span><span class="n">simulated_fit_iter</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="n">sfit</span><span class="p">)</span>
        <span class="n">sE</span> <span class="o">=</span> <span class="n">sfit</span><span class="o">.</span><span class="n">p</span><span class="p">[</span><span class="s">&#39;E&#39;</span><span class="p">]</span>             <span class="c"># best-fit parameters (simulation)</span>
        <span class="n">sa</span> <span class="o">=</span> <span class="n">sfit</span><span class="o">.</span><span class="n">p</span><span class="p">[</span><span class="s">&#39;a&#39;</span><span class="p">]</span>
        <span class="n">E</span> <span class="o">=</span> <span class="n">sfit</span><span class="o">.</span><span class="n">pexact</span><span class="p">[</span><span class="s">&#39;E&#39;</span><span class="p">]</span>         <span class="c"># correct results for parameters</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">sfit</span><span class="o">.</span><span class="n">pexact</span><span class="p">[</span><span class="s">&#39;a&#39;</span><span class="p">]</span>
        <span class="k">print</span><span class="p">(</span><span class="s">&#39;E1/E0 =&#39;</span><span class="p">,</span> <span class="n">sE</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">sE</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s">&#39;  E2/E0 =&#39;</span><span class="p">,</span> <span class="n">sE</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">/</span> <span class="n">sE</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">print</span><span class="p">(</span><span class="s">&#39;a1/a0 =&#39;</span><span class="p">,</span> <span class="n">sa</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">sa</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s">&#39;  a2/a0 =&#39;</span><span class="p">,</span> <span class="n">sa</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">/</span> <span class="n">sa</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">print</span><span class="p">(</span><span class="s">&#39;</span><span class="se">\n</span><span class="s">Simulated Fit Values - Exact Values:&#39;</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span>
            <span class="s">&#39;E1/E0:&#39;</span><span class="p">,</span> <span class="p">(</span><span class="n">sE</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">sE</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">-</span> <span class="p">(</span><span class="n">E</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">E</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
            <span class="s">&#39;  E2/E0:&#39;</span><span class="p">,</span> <span class="p">(</span><span class="n">sE</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">/</span> <span class="n">sE</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">-</span> <span class="p">(</span><span class="n">E</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">/</span> <span class="n">E</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="p">)</span>
        <span class="k">print</span><span class="p">(</span>
            <span class="s">&#39;a1/a0:&#39;</span><span class="p">,</span> <span class="p">(</span><span class="n">sa</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">sa</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">-</span> <span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
            <span class="s">&#39;  a2/a0:&#39;</span><span class="p">,</span> <span class="p">(</span><span class="n">sa</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">/</span> <span class="n">sa</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">-</span> <span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">/</span> <span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="p">)</span>

        <span class="c"># compute chi**2 comparing selected fit results to exact results</span>
        <span class="n">sim_results</span> <span class="o">=</span> <span class="p">[</span><span class="n">sE</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">sE</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">sa</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">sa</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
        <span class="n">exact_results</span> <span class="o">=</span> <span class="p">[</span><span class="n">E</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">E</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
        <span class="n">chi2</span> <span class="o">=</span> <span class="n">gv</span><span class="o">.</span><span class="n">chi2</span><span class="p">(</span><span class="n">sim_results</span><span class="p">,</span> <span class="n">exact_results</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span>
            <span class="s">&#39;</span><span class="se">\n</span><span class="s">Parameter chi2/dof [dof] = </span><span class="si">%.2f</span><span class="s">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">chi2</span> <span class="o">/</span> <span class="n">gv</span><span class="o">.</span><span class="n">chi2</span><span class="o">.</span><span class="n">dof</span><span class="p">),</span>
            <span class="s">&#39;[</span><span class="si">%d</span><span class="s">]&#39;</span> <span class="o">%</span> <span class="n">gv</span><span class="o">.</span><span class="n">chi2</span><span class="o">.</span><span class="n">dof</span><span class="p">,</span>
            <span class="s">&#39;  Q = </span><span class="si">%.1f</span><span class="s">&#39;</span> <span class="o">%</span> <span class="n">gv</span><span class="o">.</span><span class="n">chi2</span><span class="o">.</span><span class="n">Q</span>
            <span class="p">)</span>
</pre></div>
</div>
<p>The fit data for each of the three simulations is the same as the original fit
data except that the means have been adjusted (randomly) so the correct values
for the fit parameters are in each case equal to <code class="docutils literal"><span class="pre">pexact=fit.pmean</span></code>.
Simulation fit results will typically differ from the correct values by
an amount of order a standard deviation. With  sufficiently accurate data,
the results from a large number
of simulations will be distributed in Gaussians centered on the correct
values (<code class="docutils literal"><span class="pre">pexact</span></code>), with widths that equal the standard deviations
given by the fit (<code class="docutils literal"><span class="pre">fit.psdev</span></code>). (With less accurate data, the
distributions may become non-Gaussian, and the interpretation of fit
results more complicated.)</p>
<p>In the present example, the output from the three simulations is:</p>
<div class="highlight-python"><div class="highlight"><pre>************************************* simulation
Least Square Fit:
  chi2/dof [dof] = 0.43 [15]    Q = 0.97    logGBF = 227.47

Parameters:
            a 0    0.4064 (40)      [  0.50 (50) ]  
              1    0.4049 (42)      [  0.50 (50) ]  
              2     0.414 (12)      [  0.50 (50) ]  
              3     0.354 (46)      [  0.50 (50) ]  
              4      0.57 (16)      [  0.50 (50) ]  
              5      0.35 (31)      [  0.50 (50) ]  
              6      0.38 (42)      [  0.50 (50) ]  
            E 0   0.90123 (50)      [  1.00 (50) ]  
              1    1.7997 (11)      [  1.90 (50) ]  
              2     2.699 (10)      [  2.80 (50) ]  
              3     3.599 (14)      [  3.70 (50) ]  
              4     4.499 (17)      [  4.60 (50) ]  
              5     5.399 (20)      [  5.50 (50) ]  
              6     6.299 (22)      [  6.40 (50) ]  

Settings:
  svdcut/n = None/0    reltol/abstol = 0.0001/0    (itns/time = 40/0.0)

E1/E0 = 1.9969(11)   E2/E0 = 2.995(11)
a1/a0 = 0.9963(26)   a2/a0 = 1.019(28)

Simulated Fit Values - Exact Values:
E1/E0: -0.0025(11)   E2/E0: -0.005(11)
a1/a0: -0.0033(26)   a2/a0: 0.014(28)
</pre></div>
</div>
<p>The simulations show that the fit values usually agree with the correct
values to within a standard deviation or so (the correct results here are
the mean values from the last fit discussed in <a class="reference internal" href="#correlated-parameters"><span>Correlated Parameters; Gaussian Bayes Factor</span></a>).
Furthermore the error estimates for each parameter from
the original fit are reproduced by the simulations. We also compute
the <code class="docutils literal"><span class="pre">chi**2</span></code> for the difference between the leading fit parameters and
the exact values. This checks parameter values, standard deviations, and correlations.
The results are reasonable for four degrees of freedom. Here the first simulation
shows results that are off by a third of a standard deviation on average, but
this is not so unusual &#8212; the <code class="docutils literal"><span class="pre">Q=0.1</span></code> indicates that it happens 10% of the time.</p>
<p>More thorough testing is possible: for example, one could run many simulations
(100?) to verify that the distribution of (simulation) fit results is Gaussian,
centered around <code class="docutils literal"><span class="pre">pexact</span></code>. This is overkill in most
situations, however. The three simulations above are enough to reassure
us that the original fit estimates, including errors, are reliable.</p>
</div>
<div class="section" id="positive-parameters-non-gaussian-priors">
<h2>Positive Parameters; Non-Gaussian Priors<a class="headerlink" href="#positive-parameters-non-gaussian-priors" title="Permalink to this headline">¶</a></h2>
<p>The priors for <a class="reference internal" href="lsqfit.html#lsqfit.nonlinear_fit" title="lsqfit.nonlinear_fit"><code class="xref py py-class docutils literal"><span class="pre">lsqfit.nonlinear_fit</span></code></a> are all Gaussian. There are situations,
however, where other distributions would be desirable. One such case is where
a parameter is known to be positive, but is close to zero in value (&#8220;close&#8221;
being defined relative to the <em>a priori</em> uncertainty). For such cases we would
like to use  non-Gaussian priors that force positivity &#8212; for example, priors
that  impose log-normal or exponential distributions on the parameter.
Ideally the decision to use such a distribution is made on a parameter-
by-parameter basis, when creating the priors, and has no impact on the
definition of the fit function itself.</p>
<p><a class="reference internal" href="lsqfit.html#lsqfit.nonlinear_fit" title="lsqfit.nonlinear_fit"><code class="xref py py-class docutils literal"><span class="pre">lsqfit.nonlinear_fit</span></code></a> supports log-normal distributions when <code class="docutils literal"><span class="pre">extend=True</span></code> is set
in its argument list. This argument only affects fits that use dictionaries
for their parameters. The prior for a parameter <code class="docutils literal"><span class="pre">'c'</span></code> is switched from a
Gaussian distribution to a log-normal distribtuion by replacing parameter
<code class="docutils literal"><span class="pre">'c'</span></code> in the fit prior with a prior for its logarithm, using the key
<code class="docutils literal"><span class="pre">'log(c)'</span></code>. This causes <a class="reference internal" href="lsqfit.html#lsqfit.nonlinear_fit" title="lsqfit.nonlinear_fit"><code class="xref py py-class docutils literal"><span class="pre">lsqfit.nonlinear_fit</span></code></a> to use the logarithm as the fit
parameter (with its Gaussian prior). Parameter dictionaries produced by
<a class="reference internal" href="lsqfit.html#lsqfit.nonlinear_fit" title="lsqfit.nonlinear_fit"><code class="xref py py-class docutils literal"><span class="pre">lsqfit.nonlinear_fit</span></code></a> will have entries for both <code class="docutils literal"><span class="pre">'c'</span></code> and <code class="docutils literal"><span class="pre">'log(c)'</span></code>, so only
the prior need be changed to switch distributions. In particular the fit
function can be expressed directly in terms of <code class="docutils literal"><span class="pre">'c'</span></code> so that it is
independent of the distribution chosen for the <code class="docutils literal"><span class="pre">'c'</span></code> prior.</p>
<p>To illustrate consider a simple problem where an experimental quantity <code class="docutils literal"><span class="pre">y</span></code> is
known to be positive, but experimental errors mean that measured values can
often be negative:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">gvar</span> <span class="kn">as</span> <span class="nn">gv</span>
<span class="kn">import</span> <span class="nn">lsqfit</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">gv</span><span class="o">.</span><span class="n">gvar</span><span class="p">([</span>
   <span class="s">&#39;-0.17(20)&#39;</span><span class="p">,</span> <span class="s">&#39;-0.03(20)&#39;</span><span class="p">,</span> <span class="s">&#39;-0.39(20)&#39;</span><span class="p">,</span> <span class="s">&#39;0.10(20)&#39;</span><span class="p">,</span> <span class="s">&#39;-0.03(20)&#39;</span><span class="p">,</span>
   <span class="s">&#39;0.06(20)&#39;</span><span class="p">,</span> <span class="s">&#39;-0.23(20)&#39;</span><span class="p">,</span> <span class="s">&#39;-0.23(20)&#39;</span><span class="p">,</span> <span class="s">&#39;-0.15(20)&#39;</span><span class="p">,</span> <span class="s">&#39;-0.01(20)&#39;</span><span class="p">,</span>
   <span class="s">&#39;-0.12(20)&#39;</span><span class="p">,</span> <span class="s">&#39;0.05(20)&#39;</span><span class="p">,</span> <span class="s">&#39;-0.09(20)&#39;</span><span class="p">,</span> <span class="s">&#39;-0.36(20)&#39;</span><span class="p">,</span> <span class="s">&#39;0.09(20)&#39;</span><span class="p">,</span>
   <span class="s">&#39;-0.07(20)&#39;</span><span class="p">,</span> <span class="s">&#39;-0.31(20)&#39;</span><span class="p">,</span> <span class="s">&#39;0.12(20)&#39;</span><span class="p">,</span> <span class="s">&#39;0.11(20)&#39;</span><span class="p">,</span> <span class="s">&#39;0.13(20)&#39;</span>
   <span class="p">])</span>
</pre></div>
</div>
<p>We want to know the average value <code class="docutils literal"><span class="pre">a</span></code> of the <code class="docutils literal"><span class="pre">y</span></code>s and so could
use the following fitting code:</p>
<div class="highlight-python"><div class="highlight"><pre>prior = gv.BufferDict()
prior[&#39;a&#39;] = gv.gvar(0.02, 0.02))                # a = avg value of y&#39;s

def fcn(p, N=len(y)):
   return N * [p[&#39;a&#39;]]

fit = lsqfit.nonlinear_fit(prior=prior, data=y, fcn=fcn)
print(fit)
print(&#39;a =&#39;, fit.p[&#39;a&#39;].fmt())
</pre></div>
</div>
<p>where we are assuming <em>a priori</em> information that suggests
the average is around 0.02. The output from this code is:</p>
<div class="highlight-python"><div class="highlight"><pre>Least Square Fit:
  chi2/dof [dof] = 0.84 [20]    Q = 0.67    logGBF = 5.3431

Parameters:
              a   0.004 (18)     [ 0.020 (20) ]  

Settings:
  svdcut/n = 1e-15/0    reltol/abstol = 0.0001/0    (itns/time = 2/0.0)

a = 0.004(18)
</pre></div>
</div>
<p>This is not such a useful result since much of the one-sigma range for <code class="docutils literal"><span class="pre">a</span></code>
is negative, and yet we know that <code class="docutils literal"><span class="pre">a</span></code> must be postive.</p>
<p>A better analysis is to use a log-normal distribution for <code class="docutils literal"><span class="pre">a</span></code>:</p>
<div class="highlight-python"><div class="highlight"><pre>prior = gv.BufferDict()
prior[&#39;log(a)&#39;] = gv.log(gv.gvar(0.02, 0.02))) # loga not a

def fcn(p, N=len(y)):
   return N * [p[&#39;a&#39;]]

fit = lsqfit.nonlinear_fit(prior=prior, data=y, fcn=fcn, extend=True)
print(fit)
print(&#39;a =&#39;, fit.p[&#39;a&#39;].fmt())                 # exp(log(a))
</pre></div>
</div>
<p>The fit parameter is now <code class="docutils literal"><span class="pre">log(a)</span></code> rather than <code class="docutils literal"><span class="pre">a</span></code> itself, but the code
is unchanged except for the definition of the prior and the addition
of <code class="docutils literal"><span class="pre">extend=True</span></code> to the <a class="reference internal" href="lsqfit.html#lsqfit.nonlinear_fit" title="lsqfit.nonlinear_fit"><code class="xref py py-class docutils literal"><span class="pre">lsqfit.nonlinear_fit</span></code></a> arguments. In particular the
fit function is identical to what we used in the first case.</p>
<p>The result from this fit is</p>
<div class="highlight-python"><div class="highlight"><pre>Least Square Fit:
  chi2/dof [dof] = 0.85 [20]    Q = 0.65    logGBF = 5.252

Parameters:
         log(a)   -4.44 (97)     [ -3.9 (1.0) ]  
-----------------------------------------------
              a   0.012 (11)     [ 0.020 (20) ]  

Settings:
  svdcut/n = 1e-15/0    reltol/abstol = 0.0001/0*    (itns/time = 12/0.0)

a = 0.012(11)
</pre></div>
</div>
<p>which is more compelling. Parameters listed  above the dashed line in the
parameter table are the actual  parameters used in the fit; those listed below
the dashed line are derived from those above the line. The &#8220;correct&#8221; value for
<code class="docutils literal"><span class="pre">a</span></code> here is 0.015 (from the method used to generate the <code class="docutils literal"><span class="pre">y</span></code>s).</p>
<p>Setting <code class="docutils literal"><span class="pre">extend=True</span></code> in <a class="reference internal" href="lsqfit.html#lsqfit.nonlinear_fit" title="lsqfit.nonlinear_fit"><code class="xref py py-class docutils literal"><span class="pre">lsqfit.nonlinear_fit</span></code></a> also allows parameters to  be
replaced by their square roots as fit parameters &#8212; for example,  define
<code class="docutils literal"><span class="pre">`prior['sqrt(a)']</span></code> rather than <code class="docutils literal"><span class="pre">prior['a']</span></code> when
creating the prior. This again guarantees positive  parameters.
Using <code class="docutils literal"><span class="pre">prior['sqrt(a)'']=gv.sqrt(gv.gvar(0.02,</span> <span class="pre">0.02))</span></code> in the prior above, instead
of  <code class="docutils literal"><span class="pre">a=gv.gvar(0.02,</span> <span class="pre">0.02)</span></code>, leads to a final result of <code class="docutils literal"><span class="pre">a</span> <span class="pre">=</span> <span class="pre">0.010(13)</span></code>,
which is almost identical to the result obtained from the log-normal
distribution. Note that a sqrt-normal distribution with zero mean is
equivalent to an exponential distribution.</p>
<p>Other distributions can be defined using <a class="reference internal" href="lsqfit.html#lsqfit.add_parameter_distribution" title="lsqfit.add_parameter_distribution"><code class="xref py py-meth docutils literal"><span class="pre">lsqfit.add_parameter_distribution()</span></code></a>.
For example,</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">lsqfit</span>
<span class="kn">import</span> <span class="nn">gvar</span> <span class="kn">as</span> <span class="nn">gv</span>

<span class="k">def</span> <span class="nf">invf</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="k">return</span> <span class="mf">0.02</span> <span class="o">+</span> <span class="mf">0.02</span> <span class="o">*</span> <span class="n">gv</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">gv</span><span class="o">.</span><span class="n">arctanh</span><span class="p">((</span><span class="n">x</span> <span class="o">-</span> <span class="mf">0.02</span><span class="p">)</span> <span class="o">/</span> <span class="mf">0.02</span><span class="p">)</span>

<span class="n">lsqfit</span><span class="o">.</span><span class="n">add_parameter_distribution</span><span class="p">(</span><span class="s">&#39;f&#39;</span><span class="p">,</span> <span class="n">invf</span><span class="p">)</span>
<span class="n">prior</span> <span class="o">=</span> <span class="n">gv</span><span class="o">.</span><span class="n">BufferDict</span><span class="p">()</span>
<span class="n">prior</span><span class="p">[</span><span class="s">&#39;f(a)&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gv</span><span class="o">.</span><span class="n">gvar</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>

<span class="o">...</span> <span class="k">as</span> <span class="n">before</span> <span class="o">...</span>
</pre></div>
</div>
<p>does a fit with Gaussian parameter <code class="docutils literal"><span class="pre">f(a)</span></code>, which forces <code class="docutils literal"><span class="pre">a</span></code>
to lie between 0 and 0.2. This fit gives <code class="docutils literal"><span class="pre">a=0.009(13)</span></code>, which
again agrees well with log-normal fit.</p>
</div>
<div class="section" id="debugging-and-troubleshooting">
<h2>Debugging and Troubleshooting<a class="headerlink" href="#debugging-and-troubleshooting" title="Permalink to this headline">¶</a></h2>
<p>It is a very good idea to set parameter <code class="docutils literal"><span class="pre">debug=True</span></code> in <a class="reference internal" href="lsqfit.html#lsqfit.nonlinear_fit" title="lsqfit.nonlinear_fit"><code class="xref py py-class docutils literal"><span class="pre">lsqfit.nonlinear_fit</span></code></a>, at
least in the early stages of a project. This causes the code to look for
common mistakes and report on them with  more intelligible error messages. The
code also then checks for significant roundoff errors in the matrix inversion
of the covariance matrice.</p>
<p>A common mistake is a mismatch between the format of the data and the
format of what comes back from the fit function. Another mistake is when  a
fit function <code class="docutils literal"><span class="pre">fcn(p)</span></code> returns results containing <code class="xref py py-class docutils literal"><span class="pre">gvar.GVar</span></code>s  when the
parameters <code class="docutils literal"><span class="pre">p</span></code> are all just numbers (or arrays of numbers). The only way a
<code class="xref py py-class docutils literal"><span class="pre">gvar.GVar</span></code> should get into a fit  function is through the parameters; if a fit
function requires an extra <code class="xref py py-class docutils literal"><span class="pre">gvar.GVar</span></code>, that <code class="xref py py-class docutils literal"><span class="pre">gvar.GVar</span></code> should be turned into a
parameter by adding it to the prior.</p>
<p>Error messages that come from inside the <em>gsl</em> routines used by
<a class="reference internal" href="lsqfit.html#lsqfit.nonlinear_fit" title="lsqfit.nonlinear_fit"><code class="xref py py-class docutils literal"><span class="pre">lsqfit.nonlinear_fit</span></code></a> are sometimes less than useful. They are usually due to errors
in one of the inputs to the fit  (that is, the fit data, the prior, or the fit
function). Again setting <code class="docutils literal"><span class="pre">debug=True</span></code> may catch the errors before they
land in <em>gsl</em>.</p>
<p>Occasionally <a class="reference internal" href="lsqfit.html#lsqfit.nonlinear_fit" title="lsqfit.nonlinear_fit"><code class="xref py py-class docutils literal"><span class="pre">lsqfit.nonlinear_fit</span></code></a> appears to go crazy, with gigantic
<code class="docutils literal"><span class="pre">chi**2</span></code>s (<em>e.g.</em>, <code class="docutils literal"><span class="pre">1e78</span></code>). This could be because there is a genuine
zero-eigenvalue mode in the covariance matrix of the data or prior. Such a
zero mode makes it impossible to invert the covariance matrix when evaluating
<code class="docutils literal"><span class="pre">chi**2</span></code>. One fix is to include SVD cuts in the fit by setting, for
example, <code class="docutils literal"><span class="pre">svdcut=(1e-14,1e-14)</span></code> in the call to <a class="reference internal" href="lsqfit.html#lsqfit.nonlinear_fit" title="lsqfit.nonlinear_fit"><code class="xref py py-class docutils literal"><span class="pre">lsqfit.nonlinear_fit</span></code></a>.
These cuts will exclude exact or nearly exact zero modes, while leaving
important modes mostly unaffected.</p>
<p>Even if the SVD cuts work in such a case, the question remains as to why one
of the covariance matrices has a zero mode. A common cause is if the same
<code class="xref py py-class docutils literal"><span class="pre">gvar.GVar</span></code> was used for more than one prior. For example, one might
think that</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">gvar</span> <span class="kn">as</span> <span class="nn">gv</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">z</span> <span class="o">=</span> <span class="n">gv</span><span class="o">.</span><span class="n">gvar</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">prior</span> <span class="o">=</span> <span class="n">gv</span><span class="o">.</span><span class="n">BufferDict</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="n">z</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="n">z</span><span class="p">)</span>
</pre></div>
</div>
<p>creates a prior 1±1 for each of parameter <code class="docutils literal"><span class="pre">a</span></code> and parameter <code class="docutils literal"><span class="pre">b</span></code>.
Indeed each parameter separately is of order 1±1, but in a fit the two
parameters would be forced equal to each other because their priors are both
set equal to the same <code class="xref py py-class docutils literal"><span class="pre">gvar.GVar</span></code>, <code class="docutils literal"><span class="pre">z</span></code>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">prior</span><span class="p">[</span><span class="s">&#39;a&#39;</span><span class="p">],</span> <span class="n">prior</span><span class="p">[</span><span class="s">&#39;b&#39;</span><span class="p">])</span>
<span class="go">1.0(1.0) 1.0(1.0)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">prior</span><span class="p">[</span><span class="s">&#39;a&#39;</span><span class="p">]</span><span class="o">-</span><span class="n">prior</span><span class="p">[</span><span class="s">&#39;b&#39;</span><span class="p">])</span>
<span class="go">0(0)</span>
</pre></div>
</div>
<p>That is, while parameters <code class="docutils literal"><span class="pre">a</span></code> and <code class="docutils literal"><span class="pre">b</span></code> fluctuate over a range of
1±1, they fluctuate together, in exact lock-step. The covariance matrix
for <code class="docutils literal"><span class="pre">a</span></code> and <code class="docutils literal"><span class="pre">b</span></code> must therefore be singular, with a zero mode corresponding
to the combination <code class="docutils literal"><span class="pre">a-b</span></code>; it is all 1s in this case:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cov</span> <span class="o">=</span> <span class="n">gv</span><span class="o">.</span><span class="n">evalcov</span><span class="p">(</span><span class="n">prior</span><span class="o">.</span><span class="n">flat</span><span class="p">)</span>    <span class="c"># prior&#39;s covariance matrix</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">det</span><span class="p">(</span><span class="n">cov</span><span class="p">))</span>       <span class="c"># determinant is zero</span>
<span class="go">0.0</span>
</pre></div>
</div>
<p>This zero mode upsets <code class="xref py py-func docutils literal"><span class="pre">nonlinear_fit()</span></code>. If <code class="docutils literal"><span class="pre">a</span></code> and <code class="docutils literal"><span class="pre">b</span></code> are meant to
fluctuate together then an SVD cut as above will give correct results (with
<code class="docutils literal"><span class="pre">a</span></code> and <code class="docutils literal"><span class="pre">b</span></code> being forced equal to several decimal places, depending upon
the cut). Of course, simply replacing <code class="docutils literal"><span class="pre">b</span></code> by <code class="docutils literal"><span class="pre">a</span></code> in the fit function would
be even better. If, on the other hand, <code class="docutils literal"><span class="pre">a</span></code> and <code class="docutils literal"><span class="pre">b</span></code> were not meant to
fluctuate together, the prior should be redefined:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">prior</span> <span class="o">=</span> <span class="n">gv</span><span class="o">.</span><span class="n">BufferDict</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="n">gv</span><span class="o">.</span><span class="n">gvar</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">b</span><span class="o">=</span><span class="n">gv</span><span class="o">.</span><span class="n">gvar</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
<p>where now each parameter has its own <code class="xref py py-class docutils literal"><span class="pre">gvar.GVar</span></code>.</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Overview and Tutorial</a><ul>
<li><a class="reference internal" href="#introduction">Introduction</a></li>
<li><a class="reference internal" href="#gaussian-random-variables-and-error-propagation">Gaussian Random Variables and Error Propagation</a></li>
<li><a class="reference internal" href="#basic-fits">Basic Fits</a></li>
<li><a class="reference internal" href="#chained-fits">Chained Fits</a></li>
<li><a class="reference internal" href="#x-has-error-bars"><code class="docutils literal"><span class="pre">x</span></code> has Error Bars</a></li>
<li><a class="reference internal" href="#correlated-parameters-gaussian-bayes-factor">Correlated Parameters; Gaussian Bayes Factor</a></li>
<li><a class="reference internal" href="#tuning-priors-and-the-empirical-bayes-criterion">Tuning Priors and the Empirical Bayes Criterion</a></li>
<li><a class="reference internal" href="#partial-errors-and-error-budgets">Partial Errors and Error Budgets</a></li>
<li><a class="reference internal" href="#y-has-no-error-bars"><code class="docutils literal"><span class="pre">y</span></code> has No Error Bars</a></li>
<li><a class="reference internal" href="#svd-cuts-and-roundoff-error">SVD Cuts and Roundoff Error</a></li>
<li><a class="reference internal" href="#bootstrap-error-analysis">Bootstrap Error Analysis</a></li>
<li><a class="reference internal" href="#testing-fits-with-simulated-data">Testing Fits with Simulated Data</a></li>
<li><a class="reference internal" href="#positive-parameters-non-gaussian-priors">Positive Parameters; Non-Gaussian Priors</a></li>
<li><a class="reference internal" href="#debugging-and-troubleshooting">Debugging and Troubleshooting</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="index.html"
                        title="previous chapter">lsqfit Documentation</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="case-extrapolation.html"
                        title="next chapter">Case Study: Simple Extrapolation</a></p>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="case-extrapolation.html" title="Case Study: Simple Extrapolation"
             >next</a> |</li>
        <li class="right" >
          <a href="index.html" title="lsqfit Documentation"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">lsqfit 7.1.0 documentation</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &copy; Copyright 2009-2014, G. P. Lepage.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.3.1.
    </div>
  </body>
</html>